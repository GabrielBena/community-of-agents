{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm as tqdm_n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchsummary import summary\n",
    "from copy import copy, deepcopy\n",
    "from tqdm.notebook import tqdm, trange\n",
    "import ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.data.datasets import get_datasets_symbols\n",
    "from community.utils.plotting import plot_grid, create_gifs\n",
    "from community.data.tasks import get_task_target, get_task_family_dict, get_factors_list\n",
    "from community.utils.configs import configure_readouts\n",
    "from community.common.models.ensembles import Community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_agents = 2\n",
    "n_classes_per_digit = 10\n",
    "\n",
    "n_classes = n_classes_per_digit * n_agents\n",
    "\n",
    "data_config = {\n",
    "    \"data_size\": (50000, 5000),\n",
    "    \"nb_steps\": 50,\n",
    "    \"n_symbols\": n_classes - 1,\n",
    "    \"symbol_type\": \"mod_5\",\n",
    "    \"input_size\": 60,\n",
    "    \"static\": True,\n",
    "    \"common_input\": False,\n",
    "    \"n_diff_symbols\": n_agents,\n",
    "    \"parallel\": False,\n",
    "}\n",
    "\n",
    "if data_config[\"static\"]:\n",
    "    data_config[\"nb_steps\"] = 10\n",
    "    data_config[\"data_size\"] = [d for d in data_config[\"data_size\"]]\n",
    "\n",
    "n_bits = np.ceil(np.log2(n_classes)).astype(int)\n",
    "# loaders, datasets = get_datasets_symbols(data_config, batch_size, use_cuda, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cProfile as profile\n",
    "import pstats\n",
    "\n",
    "# prof = profile.Profile()\n",
    "# prof.enable()\n",
    "# prof.disable()\n",
    "# stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "# stats.print_stats(30)  # top 10 rows\n",
    "\n",
    "loaders, datasets = get_datasets_symbols(data_config, batch_size, use_cuda, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = datasets[0].data[:-1]\n",
    "s = 50\n",
    "fig, axs = plt.subplots(1, 5, figsize=(30, 20))\n",
    "for i, ax in enumerate(axs):\n",
    "    if not data_config[\"common_input\"]:\n",
    "        ax.imshow(data[i + s][-1].reshape(120, 60))\n",
    "        ax.set_title(targets[i + s].data.numpy())\n",
    "    else:\n",
    "        ax.imshow(data[i + s][-1].reshape(60, 60))\n",
    "        ax.set_title(targets[i + s].data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.funcspec.single_model_loop import (\n",
    "    init_and_train,\n",
    "    train_and_compute_metrics,\n",
    "    train_community,\n",
    "    init_community,\n",
    "    init_optimizers,\n",
    ")\n",
    "\n",
    "from community.data.process import process_data\n",
    "\n",
    "from community.utils.configs import get_training_dict\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "with open(\"../../latest_config.yml\", \"r\") as config_file:\n",
    "    config = yaml.load(config_file, SafeLoader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "try shared goals with sum\n",
    "\n",
    "Implement a task str-parsing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = config[\"task\"] = [ str(i) for i in range(n_agents)]  # \"family\"  # [[str(i), str((i+1)%3)] for i in range(3)]\n",
    "# task = config[\"task\"] = [['0', '1'], ['1', '2'], ['0', '2']] #\"both\"\n",
    "task = config[\"task\"] = \"parity-both\"\n",
    "\n",
    "config[\"model\"][\"agents\"][\"n_in\"] = data_config[\"input_size\"] ** 2\n",
    "config[\"model\"][\"agents\"][\"n_hidden\"] = 50\n",
    "config[\"model\"][\"n_agents\"] = n_agents\n",
    "common_readout = config[\"model\"][\"common_readout\"] = False\n",
    "\n",
    "config[\"datasets\"][\"n_classes\"] = n_classes\n",
    "config[\"datasets\"][\"n_classes_per_digit\"] = n_classes_per_digit\n",
    "config[\"datasets\"][\"symbol_config\"][\"n_diff_symbols\"] = n_agents\n",
    "\n",
    "configure_readouts(config)\n",
    "\n",
    "config[\"model\"][\"connections\"][\"sparsity\"] = 0.1\n",
    "config[\"model\"][\"connections\"][\"comms_start\"] = \"start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community = init_community(config[\"model\"])\n",
    "\n",
    "reg_readout = 0\n",
    "\n",
    "if not reg_readout:\n",
    "    optimizer = torch.optim.Adam(community.parameters(), lr=1e-3)\n",
    "\n",
    "else:\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [p for n, p in community.named_parameters() if \"readout\" not in n], lr=1e-3\n",
    "    )\n",
    "    optimizer.add_param_group(\n",
    "        {\n",
    "            \"params\": [p for n, p in community.named_parameters() if \"readout\" in n],\n",
    "            \"lr\": 1e-3,\n",
    "            \"weight_decay\": reg_readout,\n",
    "        }\n",
    "    )\n",
    "\n",
    "config[\"use_tqdm\"] = True\n",
    "\n",
    "community.nb_connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(loaders[1]))\n",
    "data, target = process_data(data, target, symbols=True, task=task)\n",
    "data, target = data.to(device), target.to(device)\n",
    "\n",
    "out, states, fconns = community(data)\n",
    "\n",
    "print(out.shape, fconns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"training\"][\"n_epochs\"] = 20\n",
    "# config[\"task\"] = [str(i) for i in range(n_agents)]\n",
    "\n",
    "train_results = train_community(\n",
    "    community,\n",
    "    *loaders,\n",
    "    optimizers=[optimizer, None],\n",
    "    config=get_training_dict(config),\n",
    "    show_all_acc=True,\n",
    "    use_tqdm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_results[\"test_accs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retraining : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freeze_retrain = False\n",
    "\n",
    "task = config[\"task\"] = \"family\"\n",
    "# task = config[\"task\"] = 'both'\n",
    "# task = config[\"task\"] = [[\"0\", \"1\"], [\"1\", \"2\"], [\"0\", \"2\"]]\n",
    "task = config[\"task\"] = [\"0\", \"1\", \"max\", \"min\"]\n",
    "\n",
    "\n",
    "config[\"model\"][\"n_agents\"] = 2\n",
    "config[\"model\"][\"agents\"][\"n_hidden\"] = 10\n",
    "common_readout = config[\"model\"][\"common_readout\"] = True\n",
    "\n",
    "configure_readouts(config)\n",
    "\n",
    "if not freeze_retrain:\n",
    "\n",
    "    community = init_community(config[\"model\"])\n",
    "\n",
    "community.n_readouts = config[\"model\"][\"n_readouts\"]\n",
    "config[\"model\"][\"readout_n_hid\"] = 10\n",
    "config[\"model\"][\"connections\"][\"sparsity\"] = 0.0\n",
    "community.use_common_readout = True\n",
    "\n",
    "for ag in community.agents:\n",
    "    ag.dims[-1] = n_classes\n",
    "\n",
    "community.initialize_readout(\n",
    "    config[\"model\"][\"n_readouts\"],\n",
    "    config[\"model\"][\"readout_from\"],\n",
    "    config[\"model\"][\"readout_n_hid\"],\n",
    ")\n",
    "\n",
    "community.to(device)\n",
    "\n",
    "reg_readout = 1\n",
    "\n",
    "if freeze_retrain:\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        [p for n, p in community.named_parameters() if \"readout\" in n],\n",
    "        lr=1e-3,\n",
    "        weight_decay=reg_readout,\n",
    "    )\n",
    "\n",
    "else:\n",
    "    if not reg_readout:\n",
    "        optimizer = torch.optim.Adam(community.parameters(), lr=1e-3)\n",
    "    else:\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            [\n",
    "                p\n",
    "                for n, p in community.named_parameters()\n",
    "                if n not in [\"readout.0\", \"readout.1\"]\n",
    "            ],\n",
    "            lr=1e-3,\n",
    "        )\n",
    "        optimizer.add_param_group(\n",
    "            {\n",
    "                \"params\": [\n",
    "                    p\n",
    "                    for n, p in community.named_parameters()\n",
    "                    if n in [\"readout.0\", \"readout.1\"]\n",
    "                ],\n",
    "                \"lr\": 1e-3,\n",
    "                \"weight_decay\": reg_readout,\n",
    "            }\n",
    "        )\n",
    "\n",
    "data, target = next(iter(loaders[1]))\n",
    "data, target = process_data(data, target, symbols=True, task=task)\n",
    "data, target = data.to(device), target.to(device)\n",
    "\n",
    "out, states, fconns = community(data)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class New_community(nn.Module):\n",
    "    def __init__(self, community, task=\"family\") -> None:\n",
    "        super().__init__()\n",
    "        self.community = community\n",
    "        self.connections = {}\n",
    "\n",
    "        if task == \"family\":\n",
    "            self.dim_out = [len(get_factors_list(n_agents)), n_classes]\n",
    "        elif isinstance(task, list):\n",
    "            self.dim_out = [len(task), n_classes]\n",
    "        else:\n",
    "            self.dim_out = [2, n_classes_per_digit]\n",
    "\n",
    "        self.readout = nn.Linear(20, np.prod(self.dim_out))\n",
    "\n",
    "    def forward(self, x, conns=0):\n",
    "        out, states, conns = self.community(x)\n",
    "        new_out = self.readout(torch.cat([o for o in out[-1]], -1))\n",
    "        new_out = new_out.reshape(-1, *self.dim_out).transpose(0, 1).unsqueeze(0)\n",
    "\n",
    "        return new_out, states, conns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = config[\"task\"] = \"both\"\n",
    "task = config[\"task\"] = [\"0\", \"1\", \"bitand\", \"bitor\", \"max\", \"min\"]\n",
    "\n",
    "community = init_community(config[\"model\"])\n",
    "\n",
    "\n",
    "new_com = New_community(community, task).to(device)\n",
    "new_com.is_community = True\n",
    "\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    [\n",
    "        p\n",
    "        for n, p in new_com.named_parameters()\n",
    "        if n in [\"readout.weight\", \"readout.bias\"]\n",
    "    ],\n",
    "    lr=1e-3,\n",
    "    weight_decay=reg_readout,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(new_com.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(loaders[1]))\n",
    "data, target = process_data(data, target, symbols=True, task=task)\n",
    "data, target = data.to(device), target.to(device)\n",
    "\n",
    "new_com(data)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"training\"][\"n_epochs\"] = 10\n",
    "\n",
    "train_results = train_community(\n",
    "    community,\n",
    "    *loaders,\n",
    "    optimizers=[optimizer, None],\n",
    "    config=get_training_dict(config),\n",
    "    show_all_acc=True,\n",
    "    use_tqdm=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == \"family\":\n",
    "    label = [str(t.data.numpy()) for t in get_factors_list(n_agents)]\n",
    "elif isinstance(task, list):\n",
    "    label = task\n",
    "elif task in [\"both\", \"all\"]:\n",
    "    labem = [\"0\", \"1\"]\n",
    "else:\n",
    "    label = None\n",
    "plt.plot(train_results[\"test_accs\"], label=label)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Readouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if task == \"family\":\n",
    "    task_f = [t.data.numpy() for t in get_factors_list(data_config[\"n_diff_symbols\"])]\n",
    "elif isinstance(task, list):\n",
    "    task_f = task\n",
    "else:\n",
    "    task_f = [task]\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(5 * len(community.readout), 5))\n",
    "fig.suptitle(\"Readout Weights\")\n",
    "\n",
    "# create 3x1 subfigs\n",
    "subfigs = fig.subfigures(1, len(community.readout))\n",
    "if len(community.readout) == 1:\n",
    "    subfigs = [subfigs]\n",
    "\n",
    "for readout, subfig, t in zip(community.readout, subfigs, task_f):\n",
    "\n",
    "    subfig.suptitle(t)\n",
    "\n",
    "    if hasattr(readout, \"__len__\"):\n",
    "\n",
    "        if hasattr(readout[0], \"__len__\"):\n",
    "            axs = subfig.subplots(len(readout[0]) - 1, len(readout))\n",
    "            for ax_r, r in zip(axs, readout):\n",
    "                l = 0\n",
    "                for layer in r:\n",
    "                    if hasattr(layer, \"weight\"):\n",
    "                        ax = ax_r[l]\n",
    "                        w = layer.weight.cpu().data.numpy()\n",
    "                        ax.imshow(w)\n",
    "                        ax.set_title(f\"Layer {l}\")\n",
    "                        l += 1\n",
    "        else:\n",
    "            axs = subfig.subplots(\n",
    "                len(readout) - 1 * isinstance(readout, nn.Sequential), 1\n",
    "            )\n",
    "            if not hasattr(axs, \"__len__\"):\n",
    "                axs = [axs]\n",
    "            layer = 0\n",
    "            for r in readout:\n",
    "                if hasattr(r, \"weight\"):\n",
    "                    ax = axs[layer]\n",
    "                    w = r.weight.cpu().data.numpy()\n",
    "                    ax.imshow(w)\n",
    "                    if layer == 0:\n",
    "                        ax.vlines(\n",
    "                            [w.shape[1] // 2],\n",
    "                            -0.01,\n",
    "                            w.shape[0],\n",
    "                            color=\"black\",\n",
    "                            linewidth=2,\n",
    "                        )\n",
    "                    ax.set_title(f\"Readout {layer}\")\n",
    "                    layer += 1\n",
    "\n",
    "    else:\n",
    "        ax = subfig.subplots(1, 1)\n",
    "        w = readout.weight.cpu().data.numpy()\n",
    "        ax.vlines([w.shape[1] // 2], -0.01, w.shape[0], color=\"black\", linewidth=2)\n",
    "        ax.imshow(w)\n",
    "        ax.set_title(f\"{w.mean() :.4E}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global rec Matrix + Com matric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_rec_global = community.w_rec_global.data\n",
    "plt.imshow(w_rec_global)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_w = w_rec_global.abs()\n",
    "stepI = abs_w.sum(1)\n",
    "stepII = torch.pow(stepI, -0.5)\n",
    "stepIII = torch.diag(stepII)\n",
    "stepIV = torch.matrix_exp(stepIII @ abs_w @ stepIII)\n",
    "stepIV[torch.eye(abs_w.shape[0], dtype=bool)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(stepIV.data.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_metric = lambda c: (c[0] - c[1]) / c.sum()\n",
    "norms = [\"None\", 1, 2, \"fro\", \"nuc\", np.inf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.funcspec.bottleneck import readout_retrain\n",
    "\n",
    "steps = [\"mid-\", \"last\"]\n",
    "\n",
    "bottleneck_metrics = readout_retrain(\n",
    "    community,\n",
    "    loaders,\n",
    "    n_classes,\n",
    "    n_agents=config[\"model\"][\"n_agents\"],\n",
    "    n_digits=data_config[\"n_diff_symbols\"],\n",
    "    n_epochs=1,\n",
    "    use_tqdm=True,\n",
    "    symbols=True,\n",
    "    force_connections=False,\n",
    "    chosen_timesteps=steps,\n",
    "    n_hid=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det = lambda M: np.abs(np.linalg.det(M))\n",
    "\n",
    "\n",
    "def plot_metric(metric):\n",
    "\n",
    "    n_steps = len(metric)\n",
    "    fig, axs = plt.subplots(1, n_steps, figsize=(10, 3), constrained_layout=True)\n",
    "\n",
    "    if n_steps == 1:\n",
    "        axs = [axs]\n",
    "\n",
    "    for s, ax in enumerate(axs):\n",
    "\n",
    "        im = ax.imshow(metric[s])\n",
    "\n",
    "        ax.set_ylabel(\"agents\")\n",
    "        ax.set_xlabel(\"Task\")\n",
    "\n",
    "        ax.set_xticks(range(len(metric[s])))\n",
    "        ax.set_yticks(range(len(metric[s])))\n",
    "\n",
    "        fig.colorbar(im, ax=ax)\n",
    "\n",
    "        ax.set_title(\n",
    "            f\"Det = {det(metric[s]) :.3E} \\n Normed Det = {det(metric[s]) / metric[s].sum(0).prod() :.3E}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(np.stack([bottleneck_metrics[\"accs\"][:, :, s] for s in range(len(steps))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return of the masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.funcspec.masks import (\n",
    "    train_and_get_mask_metric,\n",
    "    Mask_Community,\n",
    "    get_proportions,\n",
    "    get_proportions_per_agent,\n",
    "    GetSubnet_global,\n",
    "    find_optimal_sparsity,\n",
    "    train_mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_metrics, masked_coms = train_and_get_mask_metric(\n",
    "    community,\n",
    "    0.2,\n",
    "    loaders,\n",
    "    n_tests=1,\n",
    "    n_epochs=2,\n",
    "    lr=1e-1,\n",
    "    use_optimal_sparsity=False,\n",
    "    device=torch.device(\"cuda\"),\n",
    "    use_tqdm=True,\n",
    "    symbols=True,\n",
    "    include_ih=False,\n",
    "    decision_params=config[\"training\"][\"decision_params\"],\n",
    "    chosen_timesteps=[\"last\"],\n",
    "    multi_objectives=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric(mask_metrics[\"proportions\"].transpose(-1, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_com = Mask_Community(\n",
    "    community, sparsity=1, include_ih=False, include_readout=True\n",
    ")\n",
    "# masked_com.load_state_dict(mask_metrics[\"best_states\"][-1][0])\n",
    "masked_com.proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_digit = \"0\"\n",
    "decision_params = config[\"training\"][\"decision_params\"]\n",
    "use_tqdm = True\n",
    "symbols = True\n",
    "ts = \"last\"\n",
    "\n",
    "if type(use_tqdm) is int:\n",
    "    position = use_tqdm\n",
    "    use_tqdm = True\n",
    "elif use_tqdm:\n",
    "    position = 0\n",
    "\n",
    "d_params = decision_params[::]\n",
    "d_params[0] = ts\n",
    "if \"all\" in decision_params:\n",
    "    d_params[1] = target_digit\n",
    "\n",
    "\n",
    "def test_masked_com():\n",
    "\n",
    "    training_dict = {\n",
    "        \"n_epochs\": 1,\n",
    "        \"task\": str(target_digit),\n",
    "        \"global_rewire\": False,\n",
    "        \"check_gradients\": False,\n",
    "        \"reg_factor\": 0.0,\n",
    "        \"train_connections\": False,\n",
    "        \"decision_params\": d_params,\n",
    "        \"stopping_acc\": None,\n",
    "        \"early_stop\": False,\n",
    "        \"deepR_params_dict\": {},\n",
    "        \"data_type\": \"symbols\" if symbols else None,\n",
    "        \"force_connections\": False,\n",
    "        \"n_classes\": n_classes,\n",
    "        \"n_classes_per_digit\": n_classes,\n",
    "    }\n",
    "\n",
    "    train_out = train_community(\n",
    "        masked_community,\n",
    "        *loaders,\n",
    "        (None, None),\n",
    "        config=training_dict,\n",
    "        device=device,\n",
    "        trials=(False, True),\n",
    "        use_tqdm=False,\n",
    "    )\n",
    "    return train_out\n",
    "\n",
    "\n",
    "masked_community = Mask_Community(\n",
    "    community, sparsity=1, include_ih=False, include_readout=True\n",
    ").to(device)\n",
    "\n",
    "max_out = test_masked_com()\n",
    "max_acc = max_out[\"test_accs\"].max()\n",
    "min_acc = 0.9 * max_acc\n",
    "print(f\"For Sparsity of 1, acc is {max_acc}\")\n",
    "\n",
    "\n",
    "def train_com(sparsity):\n",
    "\n",
    "    return train_mask(\n",
    "        community,\n",
    "        sparsity,\n",
    "        loaders,\n",
    "        target_digit,\n",
    "        decision_params,\n",
    "        n_epochs=1,\n",
    "        lr=1e-3,\n",
    "        device=device,\n",
    "        use_tqdm=False,\n",
    "        symbols=True,\n",
    "        include_ih=False,\n",
    "    )\n",
    "\n",
    "\n",
    "sparsity = 0.8\n",
    "masked_community, losses, accs, state = train_com(sparsity)\n",
    "\n",
    "test_acc = accs.max()\n",
    "pbar = tqdm(total=10, position=position, leave=None)\n",
    "\n",
    "pbar.set_description(\n",
    "    f\"For Mask of Sparsity {masked_community.sparsity}, Acc is {test_acc}, min_acc = {min_acc}\"\n",
    ")\n",
    "\n",
    "while True:\n",
    "    # print(test_acc, masked_community.sparsity)\n",
    "    # masked_community.set_sparsity(masked_community.sparsity * 0.9)\n",
    "    # train_out = test_masked_com()\n",
    "    # test_acc = train_out[\"test_accs\"].max()\n",
    "\n",
    "    sparsity *= 0.9\n",
    "    masked_community, losses, accs, state = train_com(sparsity)\n",
    "    test_acc = accs.max()\n",
    "    pbar.set_description(\n",
    "        f\"For Mask of Sparsity {masked_community.sparsity}, Acc is {test_acc}\"\n",
    "    )\n",
    "    pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_community.subnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = np.sum([s.data.mean() for n, s in masked_com.subnets.items()])\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\n",
    "    np.mean([s.data.mean() for n, s in masked_com.subnets.items() if n[7] == str(i)])\n",
    "    / total\n",
    "    for i in range(2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([s.data.mean() for n, s in subnets.items() if n[7] == \"0\"]) / (\n",
    "    2 * np.mean([s.data.mean() for n, s in subnets.items()])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([s.data.mean() for n, s in subnets.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_proportions(masked_com).items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "community.best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_metrics[\"test_accs\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ag in community.agents:\n",
    "    eigens = torch.linalg.eigvals(ag.w_rec).cpu().data\n",
    "    plt.figure()\n",
    "    plt.scatter(eigens.real, eigens.imag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in states.transpose(0, 1).cpu():\n",
    "    plt.figure()\n",
    "    for s in state.transpose(0, -1):\n",
    "        plt.plot(range(6), s.mean(0).cpu().data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Data Gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels, centers = datasets[0].data[1:]\n",
    "centers = centers.transpose(0, 1)\n",
    "symbols = datasets[0].symbols\n",
    "symbol_size = datasets[0].symbol_size\n",
    "centers.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = 10000\n",
    "input_size = 60\n",
    "n_steps = centers.shape[0]\n",
    "n_symbols = centers.shape[-2]\n",
    "symbol_assignments = [datasets[0].get_random_symbol_assignement(l) for l in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_grid(idxs):\n",
    "    # grids = np.zeros((n_steps, data_size, input_size, input_size))\n",
    "    time_step, data_idx, symbol = idxs\n",
    "    center_pos = centers[time_step, data_idx, symbol]\n",
    "    label = symbol_assignments[data_idx][symbol]\n",
    "    grids[\n",
    "        time_step,\n",
    "        data_idx,\n",
    "        center_pos[0] : center_pos[0] + symbol_size,\n",
    "        center_pos[1] : center_pos[1] + symbol_size,\n",
    "    ] += symbols[label]\n",
    "    # return grids\n",
    "\n",
    "\n",
    "@ray.remote\n",
    "def fill_grid_data(time_step):\n",
    "\n",
    "    grids = np.zeros((data_size, input_size, input_size))\n",
    "    for data_idx in range(data_size):\n",
    "        for symbol in range(n_symbols):\n",
    "            center_pos = centers[time_step, data_idx, symbol]\n",
    "            label = symbol_assignments[data_idx][symbol]\n",
    "            grids[\n",
    "                data_idx,\n",
    "                center_pos[0] : center_pos[0] + symbol_size,\n",
    "                center_pos[1] : center_pos[1] + symbol_size,\n",
    "            ] += symbols[label]\n",
    "\n",
    "    return grids\n",
    "\n",
    "\n",
    "def old_method():\n",
    "    grids = []\n",
    "\n",
    "    def assign_square(grid, center_pos, l, d):\n",
    "        grid[\n",
    "            d,\n",
    "            center_pos[0] : center_pos[0] + symbol_size,\n",
    "            center_pos[1] : center_pos[1] + symbol_size,\n",
    "        ] += symbols[l]\n",
    "\n",
    "    for center in centers:\n",
    "        grid = np.zeros((data_size, input_size, input_size))\n",
    "        for d in range(data_size):\n",
    "            for i, c in enumerate(center[d]):\n",
    "                # l = int(i < labels[d])\n",
    "                assign_square(grid, (c[0], c[1]), symbol_assignments[d][i], d)\n",
    "\n",
    "        grids.append(grid)\n",
    "\n",
    "    grids = np.stack(grids)\n",
    "\n",
    "    return grids\n",
    "\n",
    "\n",
    "time_data_and_sym = [\n",
    "    [t, d, i]\n",
    "    for t in range(n_steps)\n",
    "    for d in range(data_size)\n",
    "    for i in range(n_symbols)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "\n",
    "num_cpus = 24\n",
    "\n",
    "grids = np.zeros((n_steps, data_size, input_size, input_size))\n",
    "\n",
    "grids_id = ray.put(grids)\n",
    "\n",
    "\n",
    "prof = profile.Profile()\n",
    "prof.enable()\n",
    "\n",
    "grids = np.stack(ray.get([fill_grid_data.remote(idx) for idx in range(n_steps)]))\n",
    "print(grids.shape)\n",
    "\n",
    "prof.disable()\n",
    "\n",
    "stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "stats.print_stats(30)  # top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = np.zeros((n_steps, data_size, input_size, input_size))\n",
    "vect_fill = np.vectorize(fill_grid, signature=\"(N)->()\")\n",
    "\n",
    "prof = profile.Profile()\n",
    "prof.enable()\n",
    "\n",
    "grids = vect_fill(time_data_and_sym)\n",
    "print(grids.shape)\n",
    "\n",
    "prof.disable()\n",
    "\n",
    "stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "stats.print_stats(30)  # top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grids = np.zeros((n_steps, data_size, input_size, input_size))\n",
    "\n",
    "prof = profile.Profile()\n",
    "prof.enable()\n",
    "\n",
    "grids = [fill_grid(idx) for idx in time_data_and_sym]\n",
    "\n",
    "prof.disable()\n",
    "\n",
    "stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "stats.print_stats(30)  # top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = profile.Profile()\n",
    "prof.enable()\n",
    "\n",
    "grids_old = old_method()\n",
    "print(grids_old.shape)\n",
    "prof.disable()\n",
    "\n",
    "stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "stats.print_stats(30)  # top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import delayed, Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = profile.Profile()\n",
    "prof.enable()\n",
    "\n",
    "grids = np.stack([fill_grid_data(d) for d in trange(n_steps)])\n",
    "grids.shape\n",
    "\n",
    "prof.disable()\n",
    "\n",
    "stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "stats.print_stats(30)  # top 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof = profile.Profile()\n",
    "prof.enable()\n",
    "\n",
    "grids = np.stack(\n",
    "    Parallel(24, max_nbytes=1e12, backend=\"multiprocessing\")(\n",
    "        delayed(fill_grid_data)(idx) for idx in trange(n_steps)\n",
    "    )\n",
    ")\n",
    "\n",
    "prof.disable()\n",
    "\n",
    "stats = pstats.Stats(prof).strip_dirs().sort_stats(\"cumtime\")\n",
    "stats.print_stats(30)  # top 10 rows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('community')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c46eabf39b4d4e6cb6668853226ee702b3f0cb279968f228c052b13b97983d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
