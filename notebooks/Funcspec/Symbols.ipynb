{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Self Contained Model of the Funcspec Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import EMNIST\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm as tqdm_n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.data.datasets import get_datasets_symbols\n",
    "from community.common.utils import plot_grid, create_gifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 256\n",
    "n_classes = 2\n",
    "task = 'parity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data: 100%|██████████| 60000/60000 [00:00<00:00, 64471.38it/s]\n",
      "Generating Data: 100%|██████████| 60000/60000 [00:00<00:00, 79347.83it/s]\n",
      "Generating Data: 100%|██████████| 10000/10000 [00:00<00:00, 79134.68it/s]\n",
      "Generating Data: 100%|██████████| 10000/10000 [00:00<00:00, 66760.00it/s]\n"
     ]
    }
   ],
   "source": [
    "data_config = {'data_size' : (60000, 10000),\n",
    "                                'nb_steps' : 50,\n",
    "                                'n_symbols' : n_classes - 1,\n",
    "                                'symbol_size' : 5,\n",
    "                                'input_size' : 30,\n",
    "                                'static' : True                      \n",
    "    }\n",
    "\n",
    "if data_config['static'] : \n",
    "    data_config['nb_steps'] = 2\n",
    "loaders, datasets = get_datasets_symbols(data_config, batch_size, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_target(target, task) : \n",
    "    try :\n",
    "        task = int(task)\n",
    "        new_target = target[:, task]\n",
    "    except ValueError : \n",
    "\n",
    "        if task == 'parity': \n",
    "            new_target = parity_task(target)\n",
    "        elif task == 'count' : \n",
    "            new_target = symbol_count(target)\n",
    "        else : \n",
    "            raise NotImplementedError\n",
    "\n",
    "    return new_target.type(torch.LongTensor).to(target.device)\n",
    "\n",
    "def parity_task(target) : \n",
    "\n",
    "    parity = 1 - target.sum(-1)%2\n",
    "    parity_target = torch.where(parity.bool(), target[:, 0], target[:, 1])\n",
    "    return parity_target\n",
    "\n",
    "def new_parity_task(target) : \n",
    "    parity = 1 - target.sum(-1)%2\n",
    "    equal = (target[:, 0].eq(target[:, 1]))\n",
    "    parity_target = torch.where(parity.bool(), target[:, 0], target[:, 1])\n",
    "    parity_target = torch.where(equal, torch.full_like(parity_target, n_classes), parity_target)\n",
    "\n",
    "    return parity_target\n",
    "\n",
    "def process_data(data, flatten=True, symbols=True, device=device) : \n",
    "    if symbols : data =  data.permute(1, 2, 0, 3, 4)\n",
    "    if flatten : data = data.flatten(start_dim=-2) \n",
    "    \n",
    "    return data.float().to(device)\n",
    "    \n",
    "\n",
    "def get_data(task=None, flatten=True, device=device) : \n",
    "    data, target = next(iter(loaders[0]))\n",
    "    print(data.shape)\n",
    "    data = process_data(data, flatten=flatten)\n",
    "    if task : target = get_task_target(target, task)\n",
    "\n",
    "    return data, target.float().to(device)\n",
    "\n",
    "\n",
    "def symbol_count(target) : \n",
    "    new_target = torch.where(target.argmax(-1).bool(), target[:, 1], target[:, 0])\n",
    "    new_target[target[:, 0] == target[:, 1]] = 0\n",
    "    return new_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb0c7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'count'\n",
    "get_all_targets = lambda : torch.cat([t for _, t in loaders[1]])\n",
    "if False : \n",
    "    \n",
    "    all_targets = get_all_targets()\n",
    "    uniques, unique_counts = all_targets.unique(dim=0, return_counts=True)\n",
    "    task_t = get_task_target(all_targets, task)\n",
    "    task_t.unique(dim=0, return_counts=True), (all_targets[:, 0] == task_t).unique(dim=0, return_counts=True), (all_targets[:, 1] == task_t).unique(dim=0, return_counts=True)\n",
    "    digits_in = lambda d1, d2 : (torch.tensor([d1, d2]) == uniques).all(1).any()\n",
    "    digits_idx = lambda d1, d2 : (torch.tensor([d1, d2]) == uniques).all(1).float().argmax()\n",
    "    counts = np.zeros((n_classes+1, n_classes+1))\n",
    "    targets = np.zeros((n_classes+1, n_classes+1), dtype=object)\n",
    "\n",
    "    for d1 in range(n_classes) : \n",
    "        counts[d1, -1] = ((all_targets[:, 0] == task_t)[all_targets[:, 0] == d1]).sum() #unique_counts[(uniques == d1)[:, 0]].sum()\n",
    "        targets[d1, -1] = str( counts[d1, -1])\n",
    "        for d2 in range(n_classes) : \n",
    "            if digits_in(d1, d2) : \n",
    "                counts[d1, d2] = unique_counts[digits_idx(d1, d2)]\n",
    "                targets[d1, d2] = f'{get_task_target(uniques, task)[digits_idx(d1, d2)].cpu().data.item()} | {unique_counts[digits_idx(d1, d2)]}'\n",
    "            else : \n",
    "                counts[d1, d2] = -0.1\n",
    "                targets[d1, d2] = 'X'\n",
    "            counts[-1, d2] = ((all_targets[:, 1] == task_t)[all_targets[:, 1] == d2]).sum() #unique_counts[(uniques == d2)[:, 1]].sum()\n",
    "            targets[-1, d2] = str( counts[-1, d2])\n",
    "\n",
    "    counts[-1, -1] = unique_counts.sum().cpu().data.item()\n",
    "    try : \n",
    "        d0_count =  (all_targets[:, 0] == task_t).unique(dim=0, return_counts=True)[1][1]\n",
    "        print((all_targets[:, 0] == task_t).unique(dim=0, return_counts=True))\n",
    "    except IndexError : \n",
    "        d0_count = 0\n",
    "\n",
    "    try : \n",
    "        d1_count =  (all_targets[:, 1] == task_t).unique(dim=0, return_counts=True)[1][1]\n",
    "    except IndexError : \n",
    "        d1_count = 0\n",
    "\n",
    "    targets[-1, -1] = str(f'D0 : {d0_count} \\n'\n",
    "                    f'D1 : {d1_count}')\n",
    "                \n",
    "    plt.figure(figsize=(5, 5), dpi=150)\n",
    "    ax = sns.heatmap(counts, cmap=\"inferno\", annot=targets, annot_kws={'fontsize': 8}, fmt='s')\n",
    "    ax.set_title('Number of examples and global targets')\n",
    "\n",
    "    ax.set_xlabel('Digit received by Agent 1')\n",
    "    ax.set_ylabel('Digit received by Agent 0')\n",
    "    ax.set_xticklabels([str(i) for i in range(n_classes)] + ['dig=global'])\n",
    "    ax.set_yticklabels([str(i) for i in range(n_classes)] + ['dig=global'])\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([0, 1]), tensor([4989, 4995])),\n",
       " (tensor([0, 1]), tensor([4975, 5009])))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loaders, datasets = get_datasets_symbols(data_config, batch_size, use_cuda)\n",
    "all_targets = get_all_targets()\n",
    "task_t = get_task_target(all_targets, 'count')\n",
    "all_targets[:, 1].unique(return_counts=True), task_t.unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 2, 2, 30, 30])\n",
      "torch.Size([2, 2, 256, 30, 30])\n"
     ]
    }
   ],
   "source": [
    "data, target = get_data(flatten=False)\n",
    "print(data.shape)\n",
    "create_gifs(data, target, 'symbols', data_config['input_size'], 'count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothStep(torch.autograd.Function):\n",
    "    '''\n",
    "    Modified from: https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html\n",
    "    '''\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(aux, x, thr=0):\n",
    "        aux.save_for_backward(x)\n",
    "        return (x >=thr).type(x.dtype)\n",
    "\n",
    "    def backward(aux, grad_output):\n",
    "        # grad_input = grad_output.clone()\n",
    "        input, = aux.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input <= -.5] = 0\n",
    "        grad_input[input > .5] = 0\n",
    "        return grad_input\n",
    "    \n",
    "smooth_step = SmoothStep().apply\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, thr=0):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = -torch.ones_like(input)\n",
    "        out[input > thr] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "super_spike  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module) : \n",
    "\n",
    "    def __init__(self, dims, use_conv=False) : \n",
    "        super().__init__()\n",
    "        if use_conv : \n",
    "            S, W, F = 1, input_size, symbol_size\n",
    "            P = int(((S-1)*W-S+F)/2)\n",
    "            print(F, S, P)\n",
    "            self.conv = nn.Sequential(nn.Conv2d(1, 1, F, S, P), nn.Flatten())\n",
    "        else : \n",
    "            self.conv = None\n",
    "\n",
    "        self.use_bottleneck = False\n",
    "        self.dims = dims\n",
    "\n",
    "        self.cell = nn.RNN(dims[0], dims[1], 1, bias=False, batch_first=False)\n",
    "        self.readout = nn.Linear(dims[1], dims[2], bias=False)\n",
    "\n",
    "    def forward(self, input, state=None, connections=0) : \n",
    "\n",
    "        if self.conv : \n",
    "            input = self.conv(input)\n",
    "\n",
    "        if len(input.shape ) < 3 : \n",
    "            input = input.unsqueeze(0)\n",
    "\n",
    "        if state is None : \n",
    "            out, h = self.cell(input)\n",
    "        else : \n",
    "            h = state + connections\n",
    "            out, h = self.cell(input, h)\n",
    "\n",
    "        out = self.readout(out[0])\n",
    "\n",
    "        return out, h\n",
    "\n",
    "class Connection(nn.Linear) : \n",
    "    def __init__(self, dims, p, binarize=False) : \n",
    "\n",
    "        super().__init__(dims[0], dims[1], bias=False)\n",
    "\n",
    "        self.sparsity = p\n",
    "        n_in, n_out = dims\n",
    "        self.nb_non_zero = int(p*n_in*n_out)\n",
    "        w_mask = np.zeros((n_in, n_out),dtype=bool)\n",
    "        ind_in, ind_out = np.unravel_index(np.random.choice(np.arange(n_in*n_out), self.nb_non_zero, replace=False), (n_in, n_out))\n",
    "        w_mask[ind_in,ind_out] = True\n",
    "        w_mask = torch.tensor(w_mask)\n",
    "        self.register_buffer('w_mask', w_mask)\n",
    "        self.binarize = binarize\n",
    "\n",
    "        assert w_mask.sum() == self.nb_non_zero, f'Number of nonzero connection is {w_mask.sum()}, expected {self.nb_non_zero}'\n",
    "\n",
    "    def forward(self, input) : \n",
    "        out = F.linear(input, self.weight*self.w_mask)\n",
    "        assert (out != 0).float().sum(-1).max() <= self.nb_non_zero, f'{(out != 0).float().sum(-1).max()} non zero connections !'\n",
    "        if self.binarize  : \n",
    "            out = super_spike(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Ensemble(nn.Module) : \n",
    "    def __init__(self, dims, p, use_conv=False, binary_con=False) : \n",
    "\n",
    "        super().__init__()\n",
    "        self.n_in, self.n_hid, self.n_out = dims\n",
    "        self.agents = nn.ModuleList([Agent(dims, use_conv) for _ in range(2)])[::-1]\n",
    "        self.connections = nn.ModuleList([Connection([dims[1]]*2, p, binary_con) for _ in range(2)])\n",
    "        self.is_community = True\n",
    "\n",
    "    def forward(self, input): \n",
    "\n",
    "        states, outputs, conns = [None for _ in range(2)], [[] for _ in range(2)], [None for _ in range(2)]\n",
    "        \n",
    "        for t, t_input in enumerate(input) :\n",
    "            for ag, agent in enumerate(self.agents) : \n",
    "                \n",
    "                ag_input = t_input[ag]\n",
    "                \n",
    "                if t>0 : \n",
    "                    input_connect = self.connections[1-ag](states[1-ag])\n",
    "                else : \n",
    "                    input_connect = 0\n",
    "                \n",
    "                out, h = agent(ag_input, states[ag], input_connect)\n",
    "\n",
    "                states[ag] = h\n",
    "                outputs[ag].append(out)\n",
    "                conns[ag] = input_connect\n",
    "\n",
    "        outputs = torch.stack([torch.stack(o) for o in outputs], 1)\n",
    "        states = torch.stack(states, 1)[0]\n",
    "        conns = torch.stack(conns, 1)[0]\n",
    "\n",
    "        #print((outputs[-1][1] == outputs[-1][1]).all())\n",
    "\n",
    "        return outputs, [states], conns\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision(outputs, decision_params, target=None) : \n",
    "    temporal_decision, agent_decision = decision_params\n",
    "\n",
    "    if temporal_decision == 'last' : \n",
    "        outputs = outputs[-1]\n",
    "\n",
    "    else : \n",
    "        raise NotImplementedError\n",
    "\n",
    "    try : \n",
    "        deciding_ags = int(agent_decision)\n",
    "        outputs = outputs[deciding_ags]\n",
    "        deciding_ags = torch.ones(outputs.shape[0])*deciding_ags\n",
    "        return outputs, deciding_ags\n",
    "\n",
    "    except ValueError : \n",
    "\n",
    "        if agent_decision == 'loss' :\n",
    "            assert target is not None, 'Provide target for min loss decision'\n",
    "            loss, min_idxs = torch.stack([F.cross_entropy(out, target, reduction='none') for out in outputs]).min(0)\n",
    "            min_idxs = min_idxs.unsqueeze(-1).expand_as(outputs[0])\n",
    "            outputs = torch.where(~min_idxs.bool(), outputs[0], outputs[1])\n",
    "            deciding_ags = min_idxs[..., 0]\n",
    "            return outputs, deciding_ags\n",
    "\n",
    "        elif agent_decision == 'max' : \n",
    "            device = outputs.device\n",
    "            n_agents = outputs.shape[0]\n",
    "            max_out = lambda i : torch.max(outputs[i,...], axis=-1)\n",
    "            _, deciding_ags = torch.max(torch.stack([max_out(i)[0] for i in range(n_agents)]), axis=0)\n",
    "            mask_1 = deciding_ags.unsqueeze(0).unsqueeze(-1).expand_as(outputs)\n",
    "            mask_2 = torch.einsum('b, bcx -> bcx', torch.arange(n_agents).to(device), torch.ones_like(outputs))\n",
    "            mask = (mask_1 == mask_2)\n",
    "\n",
    "            return (outputs*mask).sum(0), deciding_ags\n",
    "\n",
    "        else : \n",
    "            raise NotImplementedError\n",
    "\n",
    "def check_grad(model, task_id = '0') : \n",
    "    for n, p in model.named_parameters() : \n",
    "        if 'k_params' in n or 'all_scores' in n : \n",
    "            if task_id in n : \n",
    "                return check_ind_grad(n, p)\n",
    "        else : \n",
    "            check_ind_grad(n, p)\n",
    "\n",
    "def check_ind_grad(n, p) : \n",
    "    if p.grad is not None : \n",
    "        if (p.grad == 0).all() : \n",
    "            ''\n",
    "            print(f'{n}, Zero Grad')\n",
    "        #else : print(f'{n} : {p.grad}')\n",
    "    elif p.requires_grad : \n",
    "        ''\n",
    "        print(f'{n}, None Grad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [data_config['input_size']**2, 50, n_classes]\n",
    "sparsity = 0 * 1/dims[1]**2\n",
    "\n",
    "use_conv = False\n",
    "binary_connections = True\n",
    "\n",
    "community = Ensemble(dims, sparsity, use_conv, binary_connections).to(device)\n",
    "optimizer = torch.optim.Adam(community.parameters(), lr=1e-3)\n",
    "\n",
    "#summary(community.agents[0], (1, input_size, input_size) if use_conv else (1, input_size**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 2, 2, 30, 30])\n",
      "(tensor([-1.], device='cuda:0', grad_fn=<Unique2Backward0>), tensor([25600], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "data, target = get_data(flatten=True, device=device)\n",
    "out, states, conns = community(data)\n",
    "if binary_connections : print(conns.unique(return_counts=True))\n",
    "#symbol_count(target).unique(return_counts=True), (symbol_count(target) == target[:, 0]).unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_dot(out[-1][1], dict(community.named_parameters())).render('graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3703ab959ba4334bdfbd7874bdd0a31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=32'>33</a>\u001b[0m     data[:, \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m data[:, \u001b[39m1\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=34'>35</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=36'>37</a>\u001b[0m outputs, states, conns \u001b[39m=\u001b[39m community(data)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=37'>38</a>\u001b[0m \u001b[39m#print((outputs[-1][0] == outputs[-1][1]).all())\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=38'>39</a>\u001b[0m output, deciding_ags \u001b[39m=\u001b[39m get_decision(outputs, decision_params, target)\n",
      "File \u001b[0;32m~/.conda/envs/community/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb Cell 25\u001b[0m in \u001b[0;36mEnsemble.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=81'>82</a>\u001b[0m \u001b[39melse\u001b[39;00m : \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=82'>83</a>\u001b[0m     input_connect \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=84'>85</a>\u001b[0m out, h \u001b[39m=\u001b[39m agent(ag_input, states[ag], input_connect)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=86'>87</a>\u001b[0m states[ag] \u001b[39m=\u001b[39m h\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=87'>88</a>\u001b[0m outputs[ag]\u001b[39m.\u001b[39mappend(out)\n",
      "File \u001b[0;32m~/.conda/envs/community/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb Cell 25\u001b[0m in \u001b[0;36mAgent.forward\u001b[0;34m(self, input, state, connections)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=28'>29</a>\u001b[0m \u001b[39melse\u001b[39;00m : \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=29'>30</a>\u001b[0m     h \u001b[39m=\u001b[39m state \u001b[39m+\u001b[39m connections\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=30'>31</a>\u001b[0m     out, h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcell(\u001b[39minput\u001b[39;49m, h)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=32'>33</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreadout(out[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000025vscode-remote?line=34'>35</a>\u001b[0m \u001b[39mreturn\u001b[39;00m out, h\n",
      "File \u001b[0;32m~/.conda/envs/community/lib/python3.10/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/community/lib/python3.10/site-packages/torch/nn/modules/rnn.py:471\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    470\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRNN_TANH\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 471\u001b[0m         result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mrnn_tanh(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    472\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional,\n\u001b[1;32m    473\u001b[0m                               \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    474\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    475\u001b[0m         result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mrnn_relu(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    476\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional,\n\u001b[1;32m    477\u001b[0m                               \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "decision_params = ('last', 'max') # Change to '0', '1' or 'loss'\n",
    "task = 'count'\n",
    "\n",
    "pbar = tqdm_n(range(n_epochs))\n",
    "descs = np.full((2), '', dtype=object)\n",
    "\n",
    "check_gradients = False\n",
    "\n",
    "train, test = True, True\n",
    "\n",
    "early_stop = True\n",
    "\n",
    "test_cheat = False\n",
    "\n",
    "#train_loader, test_loader = loaders if not symbols else symbol_loaders()\n",
    "#subset = len(train_loader) if not symbols else 100000\n",
    "\n",
    "for epoch in pbar : \n",
    "    train_loader, test_loader = loaders\n",
    "\n",
    "    if train : \n",
    "            \n",
    "        # Training\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader) : \n",
    "            \n",
    "            data = process_data(data, True, True, device)\n",
    "            target = get_task_target(target, task).to(device)\n",
    "            \n",
    "            if test_cheat : \n",
    "                data[:, 0] = data[:, 1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, states, conns = community(data)\n",
    "            #print((outputs[-1][0] == outputs[-1][1]).all())\n",
    "            output, deciding_ags = get_decision(outputs, decision_params, target)\n",
    "\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            if check_gradients : \n",
    "                zero_grads = np.array([((p.grad == 0).all()).cpu().data.item() for p in community.parameters() if p.grad is not None])\n",
    "                none_grads = np.array([p.grad is None for p in community.parameters()])\n",
    "                zero_params = np.array(list(dict(community.named_parameters()).keys()), dtype=object)[~none_grads][zero_grads]\n",
    "                none_params = np.array(list(dict(community.named_parameters()).keys()), dtype=object)[none_grads]\n",
    "\n",
    "                print(f'Zero params : {zero_params}')\n",
    "                print(f'None Params : {none_params}')\n",
    "                \n",
    "            optimizer.step()\n",
    "\n",
    "            pred = output.argmax(dim=-1, keepdim=True)\n",
    "            correct = pred.eq(target.view_as(pred)).sum().cpu().data.item()\n",
    "            acc = (correct / target.numel())\n",
    "\n",
    "            descs[0] = str('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.3f}, Accuracy: {}%'.format(\n",
    "                            epoch, batch_idx  * batch_size, len(train_loader.dataset),\n",
    "                            100. * batch_idx / len(train_loader), loss.item(),\n",
    "                            (np.round(100*a) for a in acc) if type(acc) is list else np.round(100*acc))\n",
    "                            )\n",
    "\n",
    "            pbar.set_description((descs.sum()))\n",
    "\n",
    "    if test : \n",
    "        acc = []\n",
    "        for batch_idx, (data, target) in enumerate(test_loader) : \n",
    "            \n",
    "            data = process_data(data, True, True, device)\n",
    "            if test_cheat : \n",
    "                data[:, 0] = data[:, 1]\n",
    "            target = get_task_target(target, task).to(device)\n",
    "\n",
    "            outputs, states, conns = community(data)\n",
    "            #print((outputs[-1][0] == outputs[-1][1]).all())\n",
    "            output, deciding_ags = get_decision(outputs, decision_params, target)\n",
    "\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            pred = output.argmax(dim=-1, keepdim=True)\n",
    "            correct = pred.eq(target.view_as(pred)).sum().cpu().data.item()\n",
    "            acc += [correct / target.numel()]\n",
    "\n",
    "        acc = np.mean(acc)\n",
    "        \n",
    "        descs[1] = str('| Test : Loss: {:.3f}, Accuracy: {}%'.format(\n",
    "                        loss.item(),\n",
    "                        (np.round(100*a) for a in acc) if type(acc) is list else np.round(100*acc))\n",
    "                        )\n",
    "\n",
    "        pbar.set_description((descs.sum()))\n",
    "\n",
    "    if acc > 0.95 and early_stop: \n",
    "            break\n",
    "            #continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_conv : \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    for ag, ax in zip(community.agents, axs) : \n",
    "        im = ax.imshow((ag.conv[0].weight.data.cpu().numpy()[0, 0]))\n",
    "\n",
    "#plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8218eb00",
   "metadata": {},
   "source": [
    "## Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfe8de",
   "metadata": {},
   "source": [
    "### Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c7ecd0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "community.to(device)\n",
    "sums = []\n",
    "nonzero_idxs = [c.w_mask.nonzero()[:, 0] for c in community.connections]\n",
    "\n",
    "for data, target in loaders[1] : \n",
    "    \n",
    "    data, target = process_data(data, True, True, device), target.to(device)\n",
    "    out, states, conns = community(data.to(device))\n",
    "    \n",
    "    #conns[-1][0].count_nonzero(dim=0)\n",
    "    #torch.stack([conns[-1][i].count_nonzero(dim=0).max() for i in range(2)])\n",
    "    #sums.append(torch.tensor([[conns[-1][i][target[:, i] == t].sum() for t in range(4)] for i in range(2)]))\n",
    "    sums.append(torch.stack([torch.stack([conns[i][target[:, 1-i] == t][:, nonzero_idxs[1-i]].sum(0) for t in range(n_classes)]) for i in range(2)]))\n",
    "\n",
    "sums = torch.stack(sums).cpu().data.numpy().mean(0)[..., 0]\n",
    "ax = sns.heatmap(sums, cmap=\"inferno\", annot=sums.round(1).astype(str), annot_kws={'fontsize': 16}, fmt='s')\n",
    "ax.set_xlabel('Digit Received by other agent')\n",
    "ax.set_ylabel('Connection received by agent : ')\n",
    "ax.set_title('Average of connections received by agents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318caa3",
   "metadata": {},
   "source": [
    " ### Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4859de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_74572/2923795011.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = target.eq(torch.tensor(t)).all(axis=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_all_targets = lambda : torch.cat([t for _, t in loaders[1]])\n",
    "\n",
    "all_targets = get_all_targets()\n",
    "\n",
    "uniques = all_targets.unique(dim=0).cpu()\n",
    "decision_means = torch.zeros(len(uniques))\n",
    "\n",
    "community.to('cpu')\n",
    "\n",
    "for b_idx, (data, target) in enumerate(loaders[1]) : \n",
    "    \n",
    "    data, target = process_data(data, True, True, 'cpu'), target.to('cpu')\n",
    "    t_target = get_task_target(target, task).cpu()\n",
    "    output, *_ = community(data)\n",
    "    output, decision_ags = get_decision(output, decision_params, target=t_target)\n",
    "\n",
    "    for i, t in enumerate(uniques) :             \n",
    "        mask = target.eq(torch.tensor(t)).all(axis=1)\n",
    "        if mask.sum() != 0 : \n",
    "            decision_means[i] += decision_ags[mask].float().cpu().sum()/mask.sum()\n",
    "\n",
    "decision_means /= b_idx +1\n",
    "\n",
    "digits_in = lambda d1, d2 : (torch.tensor([d1, d2]) == uniques).all(1).any()\n",
    "digits_idx = lambda d1, d2 : (torch.tensor([d1, d2]) == uniques).all(1).float().argmax()\n",
    "decisions = np.zeros((n_classes, n_classes))\n",
    "targets = np.zeros((n_classes, n_classes), dtype=object)\n",
    "\n",
    "for d1 in range(n_classes) : \n",
    "    for d2 in range(n_classes) : \n",
    "        if digits_in(d1, d2) : \n",
    "            decisions[d1, d2] = decision_means[digits_idx(d1, d2)]\n",
    "            targets[d1, d2] = str(get_task_target(uniques, task)[digits_idx(d1, d2)].cpu().data.item())\n",
    "        else : \n",
    "            decisions[d1, d2] = -0.1\n",
    "            targets[d1, d2] = 'X'\n",
    "            \n",
    "ax = sns.heatmap(decisions, cmap=\"inferno\", annot=targets, annot_kws={'fontsize': 16}, fmt='s')\n",
    "ax.set_title('Average decison-making agent for all targets')\n",
    "\n",
    "ax.set_xlabel('Digit received by Agent 1')\n",
    "ax.set_ylabel('Digit received by Agent 0')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "community.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcspec Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.funcspec.masks import train_and_get_mask_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b5498d18a5b4f5d8b9463a545f988bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mask Metric Trials :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2e814df5ade41ed86a3570196b1609f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch::   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "481b090e17c84995882c19abb01b34a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch::   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'proportions': array([[[0.56923077, 0.43076923],\n",
       "         [0.41538462, 0.58461538]]]),\n",
       " 'test_accs': array([[[0.91646635],\n",
       "         [1.        ]]]),\n",
       " 'test_losses': array([[[0.26264572],\n",
       "         [0.0210895 ]]]),\n",
       " 'best_states': [array([OrderedDict([('model.agents.0.cell.weight_ih_l0', tensor([[-0.0533,  0.0297, -0.0787,  ...,  0.0243, -0.1500, -0.1282],\n",
       "                 [ 0.0853,  0.1231,  0.0393,  ..., -0.0126,  0.0164, -0.0561],\n",
       "                 [-0.2064, -0.0840, -0.1307,  ...,  0.0174,  0.0348, -0.0960],\n",
       "                 ...,\n",
       "                 [ 0.0627,  0.1368, -0.0535,  ...,  0.1515, -0.0247,  0.1602],\n",
       "                 [-0.0100, -0.1515,  0.1424,  ...,  0.0387, -0.0263,  0.1210],\n",
       "                 [ 0.0909,  0.0483,  0.0157,  ...,  0.0232,  0.0820,  0.0086]],\n",
       "                device='cuda:0')), ('model.agents.0.cell.weight_hh_l0', tensor([[-0.0144, -0.0565,  0.0646,  ...,  0.0756, -0.0369, -0.0281],\n",
       "                 [-0.0303, -0.0933, -0.0030,  ..., -0.1008,  0.1664,  0.0396],\n",
       "                 [ 0.0533,  0.0754,  0.0544,  ..., -0.1083, -0.0442,  0.1633],\n",
       "                 ...,\n",
       "                 [-0.0334,  0.0905, -0.0382,  ...,  0.0529,  0.0471,  0.0291],\n",
       "                 [-0.0498,  0.0723, -0.0516,  ..., -0.0201,  0.1264,  0.1072],\n",
       "                 [ 0.0957,  0.0463,  0.0612,  ..., -0.1167, -0.0590, -0.0173]],\n",
       "                device='cuda:0')), ('model.agents.0.readout.weight', tensor([[-0.1004, -0.0950, -0.1270,  0.0129, -0.0117,  0.1236, -0.0528, -0.1112,\n",
       "                  -0.0436,  0.0424,  0.0783, -0.0873,  0.0866,  0.1086, -0.0418, -0.0800,\n",
       "                  -0.0073, -0.0728, -0.0143,  0.1104,  0.0265,  0.1406, -0.0671,  0.0099,\n",
       "                   0.0825, -0.0242, -0.0504, -0.0751, -0.0891,  0.0018, -0.0816, -0.0623,\n",
       "                   0.0339, -0.0564, -0.0445, -0.0611,  0.0089, -0.0982, -0.1091,  0.1139,\n",
       "                   0.1049, -0.0211, -0.0333,  0.0340, -0.1495, -0.0743, -0.0391,  0.0006,\n",
       "                   0.0222, -0.1072],\n",
       "                 [ 0.0161, -0.0465,  0.0779,  0.0228,  0.0129, -0.0383, -0.0314,  0.0349,\n",
       "                  -0.0643,  0.0213, -0.0736, -0.1141,  0.1144, -0.1090, -0.0507, -0.0607,\n",
       "                  -0.0737, -0.0620, -0.0783,  0.1119,  0.0484, -0.1219, -0.0575,  0.0426,\n",
       "                   0.0618,  0.0954, -0.0487,  0.0680,  0.0819, -0.0144, -0.0626, -0.1140,\n",
       "                  -0.1297,  0.1022,  0.0535, -0.0931, -0.0414, -0.0966,  0.0512,  0.0898,\n",
       "                   0.0381, -0.0409,  0.0166,  0.0872,  0.0628, -0.0509, -0.0603, -0.0368,\n",
       "                   0.0947, -0.1246]], device='cuda:0')), ('model.agents.1.cell.weight_ih_l0', tensor([[-1.8677e-01, -3.5155e-02, -3.4640e-02,  ...,  1.1231e-01,\n",
       "                  -6.3603e-02, -6.3492e-05],\n",
       "                 [ 1.0313e-01, -2.0839e-02, -1.0118e-01,  ..., -8.5479e-02,\n",
       "                  -1.4773e-01,  3.4063e-03],\n",
       "                 [ 4.3841e-02, -1.0012e-01, -3.8527e-02,  ...,  1.2699e-01,\n",
       "                  -7.7918e-02, -1.2339e-01],\n",
       "                 ...,\n",
       "                 [-1.2513e-02, -4.8259e-02,  6.6110e-03,  ...,  9.0653e-02,\n",
       "                  -3.3060e-03,  2.7581e-02],\n",
       "                 [ 3.0086e-02,  5.0498e-02, -1.2026e-01,  ..., -1.0442e-01,\n",
       "                  -2.8646e-02, -1.5130e-01],\n",
       "                 [ 2.6249e-02,  4.4800e-02, -3.4301e-02,  ..., -7.6959e-02,\n",
       "                  -1.2662e-01, -1.3695e-01]], device='cuda:0')), ('model.agents.1.cell.weight_hh_l0', tensor([[ 0.1091, -0.0397, -0.0204,  ...,  0.7054,  0.1255,  0.0432],\n",
       "                 [ 0.0589,  0.0330, -0.0148,  ..., -0.0334,  0.0859,  0.0914],\n",
       "                 [-0.1987,  0.0577, -0.0488,  ...,  0.2869, -0.1588,  0.0073],\n",
       "                 ...,\n",
       "                 [ 0.0158,  0.0995,  0.0774,  ...,  0.4528, -0.0753,  0.0763],\n",
       "                 [ 0.1306, -0.1119,  0.0180,  ...,  0.0872,  0.0954,  0.1420],\n",
       "                 [ 0.0155, -0.0529,  0.0963,  ..., -0.0718, -0.0755,  0.1023]],\n",
       "                device='cuda:0')), ('model.agents.1.readout.weight', tensor([[-3.1654e-01,  3.6221e-03,  2.9039e-02, -2.0007e-01, -3.1233e-01,\n",
       "                   6.0962e-02,  5.9227e-02, -3.0722e-01,  1.1772e-01, -8.5053e-04,\n",
       "                   2.1438e-01, -1.9976e-01, -1.5033e-01, -9.8576e-02,  1.1102e-01,\n",
       "                   2.0148e-01,  1.0085e-01, -1.0009e-01, -1.9041e-01, -3.1069e-01,\n",
       "                  -2.1596e-01, -7.5325e-02, -8.3189e-02, -2.4096e-02,  2.3193e-01,\n",
       "                   5.6370e-02,  2.6350e-01, -6.0808e-02, -7.6288e-02, -1.2596e-04,\n",
       "                  -9.9550e-02,  1.7003e-01,  2.5114e-01, -9.9369e-02,  1.9064e-01,\n",
       "                   7.9612e-02, -2.0188e-01,  6.0452e-02,  4.6411e-02, -1.1351e-02,\n",
       "                   9.3600e-02, -5.5969e-02,  1.3542e-01, -1.4297e-01,  7.8850e-02,\n",
       "                  -1.7703e-02,  3.4532e-04,  1.8128e-01, -8.1962e-02, -9.4041e-02],\n",
       "                 [ 3.2590e-01, -2.6890e-02,  1.1016e-01,  8.8091e-02,  1.0818e-01,\n",
       "                   6.7690e-02, -1.0737e-01,  2.7211e-01, -4.1787e-02, -1.9160e-01,\n",
       "                  -2.1533e-01, -1.1520e-02,  4.2583e-02,  7.6300e-02,  5.1058e-02,\n",
       "                  -3.0527e-01, -4.0647e-02,  1.0462e-01,  1.8915e-01,  2.6866e-01,\n",
       "                   2.8736e-01, -1.2105e-01, -6.6800e-02, -1.0921e-01, -1.3384e-01,\n",
       "                   1.2152e-01, -1.6178e-01, -1.1702e-01, -3.3253e-02, -2.1632e-01,\n",
       "                   1.1902e-01, -4.0910e-02, -1.9416e-01, -7.5346e-02, -1.4945e-01,\n",
       "                   6.2398e-02,  3.4736e-01,  7.0093e-02, -5.7558e-02, -2.1203e-02,\n",
       "                  -2.5252e-01,  2.7447e-01, -1.0566e-01,  1.7434e-01, -3.7688e-02,\n",
       "                  -7.4467e-02, -1.2911e-01, -1.3306e-01,  2.7510e-02, -5.6549e-02]],\n",
       "                device='cuda:0')), ('model.connections.0.weight', tensor([[ 0.0181, -0.0497,  0.0698,  ..., -0.0733, -0.1181, -0.0214],\n",
       "                 [-0.1282,  0.0849,  0.0612,  ...,  0.1069,  0.0642,  0.0851],\n",
       "                 [ 0.0766, -0.0678,  0.0126,  ..., -0.0633, -0.0745,  0.1380],\n",
       "                 ...,\n",
       "                 [-0.0956,  0.0446, -0.3496,  ..., -0.0371, -0.0880,  0.0062],\n",
       "                 [-0.1153,  0.1401, -0.1214,  ..., -0.0858,  0.1070,  0.0052],\n",
       "                 [-0.0610, -0.0474, -0.0783,  ...,  0.0514,  0.1071, -0.1160]],\n",
       "                device='cuda:0')), ('model.connections.0.w_mask', tensor([[False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 ...,\n",
       "                 [False, False,  True,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False]], device='cuda:0')), ('model.connections.1.weight', tensor([[-0.0294, -0.0377,  0.0187,  ..., -0.0010,  0.0312,  0.0750],\n",
       "                 [-0.1303,  0.0347, -0.0068,  ..., -0.0355, -0.0797, -0.0006],\n",
       "                 [-0.1057, -0.1160,  0.0933,  ...,  0.0844, -0.1097, -0.1016],\n",
       "                 ...,\n",
       "                 [ 0.0568,  0.0738, -0.0092,  ..., -0.0709, -0.0654,  0.0015],\n",
       "                 [-0.0637, -0.1338,  0.1118,  ...,  0.1348, -0.0521, -0.0304],\n",
       "                 [-0.0813,  0.1206, -0.0814,  ...,  0.1085, -0.0992, -0.0892]],\n",
       "                device='cuda:0')), ('model.connections.1.w_mask', tensor([[False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 ...,\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False]], device='cuda:0')), ('scores.0_cell_weight_hh_l0', tensor([[-0.0741,  0.1170, -0.0726,  ...,  0.0141,  0.0389, -0.0653],\n",
       "                 [-0.1062, -0.0471, -0.0454,  ...,  0.0662, -0.0507,  0.1138],\n",
       "                 [ 0.1228, -0.0205, -0.0475,  ...,  0.1089,  0.0136,  0.1717],\n",
       "                 ...,\n",
       "                 [-0.0724,  0.0242, -0.0656,  ..., -0.1028,  0.0060,  0.1219],\n",
       "                 [ 0.0933,  0.1011, -0.0653,  ...,  0.0174, -0.0259,  0.0254],\n",
       "                 [ 0.0698,  0.0149,  0.0232,  ...,  0.0113, -0.0283,  0.0457]],\n",
       "                device='cuda:0')), ('scores.0_readout_weight', tensor([[ 0.5451,  0.3188,  1.9588, -0.2255, -0.1847,  1.2807, -0.2355,  0.8648,\n",
       "                  -0.0310,  0.2972,  0.5827,  0.5288, -0.0731,  0.3220, -0.0389,  0.0849,\n",
       "                  -0.0239, -0.1747, -0.0948,  0.9838, -0.0873,  1.6649, -0.4114,  0.1886,\n",
       "                  -0.2599,  0.1419, -0.3130, -0.7460, -0.2876, -0.0934,  0.0940, -0.3269,\n",
       "                  -0.4071, -0.0425, -0.0216, -0.3265,  0.0974,  0.2340,  1.0400,  0.7144,\n",
       "                  -0.5480,  0.1409,  0.1890, -0.2036,  1.4003, -0.3003, -0.0954, -0.0275,\n",
       "                  -0.2746,  0.7776],\n",
       "                 [ 0.1273, -0.2796,  1.1532,  0.1633, -0.1303,  0.3099,  0.0681,  0.1769,\n",
       "                   0.1029, -0.1459,  0.6462, -0.7605,  0.0570,  0.3865,  0.2178,  0.0518,\n",
       "                   0.0444,  0.1090,  0.8553, -0.9200,  0.1640,  1.5300,  0.5778, -0.2432,\n",
       "                   0.0737,  0.2933,  0.2891, -0.6352, -0.2225, -0.1297, -0.1006,  0.6102,\n",
       "                  -1.7644, -0.0678, -0.0756,  0.6877,  0.2970, -0.2329,  0.4784, -0.7315,\n",
       "                   0.1413, -0.2254, -0.0270,  0.1428,  0.7435,  0.1607,  0.3860,  0.0915,\n",
       "                   1.0948, -0.9978]], device='cuda:0')), ('scores.1_cell_weight_hh_l0', tensor([[ 0.1079,  0.1199,  0.1028,  ..., -0.6239,  0.0233,  0.1012],\n",
       "                 [ 0.0165, -0.0365, -0.1081,  ...,  0.0007, -0.0869,  0.1006],\n",
       "                 [ 0.0919,  0.0345,  0.0665,  ..., -0.5422, -0.1418,  0.0595],\n",
       "                 ...,\n",
       "                 [-0.0858,  0.0676, -0.0562,  ...,  0.0628, -0.0747,  0.0397],\n",
       "                 [-0.0568, -0.0925, -0.0818,  ..., -0.0069,  0.1001,  0.0889],\n",
       "                 [ 0.0596, -0.0253,  0.0079,  ...,  0.0605,  0.0687, -0.0340]],\n",
       "                device='cuda:0')), ('scores.1_readout_weight', tensor([[ 5.6188e-02,  9.9653e-02,  3.2622e-02, -2.3717e+00, -6.8210e-02,\n",
       "                   4.7273e-02,  1.7090e-01,  1.3863e-01,  8.0552e-02,  6.6491e-03,\n",
       "                   8.7089e-02, -6.9158e-02,  4.6295e-02,  3.7086e-01,  4.1523e-02,\n",
       "                   1.4748e+00, -5.7399e-02,  9.3782e-03, -1.1078e-01,  1.4595e-01,\n",
       "                  -9.1628e-02, -1.1032e-02, -5.0914e-02,  8.4115e-02, -3.6952e-01,\n",
       "                  -9.0492e-04, -2.6525e-01, -9.9250e-02,  4.4808e-02,  5.2390e-02,\n",
       "                   5.5036e-02,  5.1719e-01,  1.0835e-01, -3.1114e-01,  1.8438e+00,\n",
       "                   2.4640e-02,  1.5111e+00, -8.5506e-02, -9.7907e-02,  6.8100e-03,\n",
       "                  -1.7922e-01, -3.9923e-02,  1.4160e-01, -5.9778e-02, -8.6583e-02,\n",
       "                   1.4683e-01, -8.1907e-04, -4.9932e-02,  4.0737e-02,  7.7712e-02],\n",
       "                 [ 1.1653e-01,  5.3349e-02,  2.6683e-01, -9.5463e-01, -1.1979e-01,\n",
       "                  -4.0631e-02,  6.2936e-01,  2.4818e-01, -1.1582e-01,  2.0680e+00,\n",
       "                  -8.1194e-02, -8.4981e-02, -1.1179e-01,  1.3120e-01,  9.1380e-02,\n",
       "                   2.0275e+00, -1.2116e-01, -7.7611e-02, -3.1870e-01,  2.8119e-02,\n",
       "                   6.8461e-02, -8.5413e-02,  1.9717e-01,  1.1782e-01, -2.1723e-01,\n",
       "                   1.6075e-02, -2.4274e-02,  6.5186e-02,  3.0360e-02, -1.0585e-01,\n",
       "                  -1.0654e-01,  1.8054e-01,  7.6348e-02,  1.7218e-01,  1.5311e+00,\n",
       "                  -4.0431e-02,  2.4352e+00, -9.7781e-02, -1.5364e-01,  8.0955e-02,\n",
       "                  -2.4683e-01, -2.0696e-01,  1.0695e-01, -1.5258e-01, -1.0304e-01,\n",
       "                  -2.9539e-01, -3.8314e-02, -5.3605e-02,  1.2425e-01, -3.8008e-02]],\n",
       "                device='cuda:0'))])                                                                                                                                                        ,\n",
       "         OrderedDict([('model.agents.0.cell.weight_ih_l0', tensor([[-0.0533,  0.0297, -0.0787,  ...,  0.0243, -0.1500, -0.1282],\n",
       "                 [ 0.0853,  0.1231,  0.0393,  ..., -0.0126,  0.0164, -0.0561],\n",
       "                 [-0.2064, -0.0840, -0.1307,  ...,  0.0174,  0.0348, -0.0960],\n",
       "                 ...,\n",
       "                 [ 0.0627,  0.1368, -0.0535,  ...,  0.1515, -0.0247,  0.1602],\n",
       "                 [-0.0100, -0.1515,  0.1424,  ...,  0.0387, -0.0263,  0.1210],\n",
       "                 [ 0.0909,  0.0483,  0.0157,  ...,  0.0232,  0.0820,  0.0086]],\n",
       "                device='cuda:0')), ('model.agents.0.cell.weight_hh_l0', tensor([[-0.0144, -0.0565,  0.0646,  ...,  0.0756, -0.0369, -0.0281],\n",
       "                 [-0.0303, -0.0933, -0.0030,  ..., -0.1008,  0.1664,  0.0396],\n",
       "                 [ 0.0533,  0.0754,  0.0544,  ..., -0.1083, -0.0442,  0.1633],\n",
       "                 ...,\n",
       "                 [-0.0334,  0.0905, -0.0382,  ...,  0.0529,  0.0471,  0.0291],\n",
       "                 [-0.0498,  0.0723, -0.0516,  ..., -0.0201,  0.1264,  0.1072],\n",
       "                 [ 0.0957,  0.0463,  0.0612,  ..., -0.1167, -0.0590, -0.0173]],\n",
       "                device='cuda:0')), ('model.agents.0.readout.weight', tensor([[-0.1004, -0.0950, -0.1270,  0.0129, -0.0117,  0.1236, -0.0528, -0.1112,\n",
       "                  -0.0436,  0.0424,  0.0783, -0.0873,  0.0866,  0.1086, -0.0418, -0.0800,\n",
       "                  -0.0073, -0.0728, -0.0143,  0.1104,  0.0265,  0.1406, -0.0671,  0.0099,\n",
       "                   0.0825, -0.0242, -0.0504, -0.0751, -0.0891,  0.0018, -0.0816, -0.0623,\n",
       "                   0.0339, -0.0564, -0.0445, -0.0611,  0.0089, -0.0982, -0.1091,  0.1139,\n",
       "                   0.1049, -0.0211, -0.0333,  0.0340, -0.1495, -0.0743, -0.0391,  0.0006,\n",
       "                   0.0222, -0.1072],\n",
       "                 [ 0.0161, -0.0465,  0.0779,  0.0228,  0.0129, -0.0383, -0.0314,  0.0349,\n",
       "                  -0.0643,  0.0213, -0.0736, -0.1141,  0.1144, -0.1090, -0.0507, -0.0607,\n",
       "                  -0.0737, -0.0620, -0.0783,  0.1119,  0.0484, -0.1219, -0.0575,  0.0426,\n",
       "                   0.0618,  0.0954, -0.0487,  0.0680,  0.0819, -0.0144, -0.0626, -0.1140,\n",
       "                  -0.1297,  0.1022,  0.0535, -0.0931, -0.0414, -0.0966,  0.0512,  0.0898,\n",
       "                   0.0381, -0.0409,  0.0166,  0.0872,  0.0628, -0.0509, -0.0603, -0.0368,\n",
       "                   0.0947, -0.1246]], device='cuda:0')), ('model.agents.1.cell.weight_ih_l0', tensor([[-1.8677e-01, -3.5155e-02, -3.4640e-02,  ...,  1.1231e-01,\n",
       "                  -6.3603e-02, -6.3492e-05],\n",
       "                 [ 1.0313e-01, -2.0839e-02, -1.0118e-01,  ..., -8.5479e-02,\n",
       "                  -1.4773e-01,  3.4063e-03],\n",
       "                 [ 4.3841e-02, -1.0012e-01, -3.8527e-02,  ...,  1.2699e-01,\n",
       "                  -7.7918e-02, -1.2339e-01],\n",
       "                 ...,\n",
       "                 [-1.2513e-02, -4.8259e-02,  6.6110e-03,  ...,  9.0653e-02,\n",
       "                  -3.3060e-03,  2.7581e-02],\n",
       "                 [ 3.0086e-02,  5.0498e-02, -1.2026e-01,  ..., -1.0442e-01,\n",
       "                  -2.8646e-02, -1.5130e-01],\n",
       "                 [ 2.6249e-02,  4.4800e-02, -3.4301e-02,  ..., -7.6959e-02,\n",
       "                  -1.2662e-01, -1.3695e-01]], device='cuda:0')), ('model.agents.1.cell.weight_hh_l0', tensor([[ 0.1091, -0.0397, -0.0204,  ...,  0.7054,  0.1255,  0.0432],\n",
       "                 [ 0.0589,  0.0330, -0.0148,  ..., -0.0334,  0.0859,  0.0914],\n",
       "                 [-0.1987,  0.0577, -0.0488,  ...,  0.2869, -0.1588,  0.0073],\n",
       "                 ...,\n",
       "                 [ 0.0158,  0.0995,  0.0774,  ...,  0.4528, -0.0753,  0.0763],\n",
       "                 [ 0.1306, -0.1119,  0.0180,  ...,  0.0872,  0.0954,  0.1420],\n",
       "                 [ 0.0155, -0.0529,  0.0963,  ..., -0.0718, -0.0755,  0.1023]],\n",
       "                device='cuda:0')), ('model.agents.1.readout.weight', tensor([[-3.1654e-01,  3.6221e-03,  2.9039e-02, -2.0007e-01, -3.1233e-01,\n",
       "                   6.0962e-02,  5.9227e-02, -3.0722e-01,  1.1772e-01, -8.5053e-04,\n",
       "                   2.1438e-01, -1.9976e-01, -1.5033e-01, -9.8576e-02,  1.1102e-01,\n",
       "                   2.0148e-01,  1.0085e-01, -1.0009e-01, -1.9041e-01, -3.1069e-01,\n",
       "                  -2.1596e-01, -7.5325e-02, -8.3189e-02, -2.4096e-02,  2.3193e-01,\n",
       "                   5.6370e-02,  2.6350e-01, -6.0808e-02, -7.6288e-02, -1.2596e-04,\n",
       "                  -9.9550e-02,  1.7003e-01,  2.5114e-01, -9.9369e-02,  1.9064e-01,\n",
       "                   7.9612e-02, -2.0188e-01,  6.0452e-02,  4.6411e-02, -1.1351e-02,\n",
       "                   9.3600e-02, -5.5969e-02,  1.3542e-01, -1.4297e-01,  7.8850e-02,\n",
       "                  -1.7703e-02,  3.4532e-04,  1.8128e-01, -8.1962e-02, -9.4041e-02],\n",
       "                 [ 3.2590e-01, -2.6890e-02,  1.1016e-01,  8.8091e-02,  1.0818e-01,\n",
       "                   6.7690e-02, -1.0737e-01,  2.7211e-01, -4.1787e-02, -1.9160e-01,\n",
       "                  -2.1533e-01, -1.1520e-02,  4.2583e-02,  7.6300e-02,  5.1058e-02,\n",
       "                  -3.0527e-01, -4.0647e-02,  1.0462e-01,  1.8915e-01,  2.6866e-01,\n",
       "                   2.8736e-01, -1.2105e-01, -6.6800e-02, -1.0921e-01, -1.3384e-01,\n",
       "                   1.2152e-01, -1.6178e-01, -1.1702e-01, -3.3253e-02, -2.1632e-01,\n",
       "                   1.1902e-01, -4.0910e-02, -1.9416e-01, -7.5346e-02, -1.4945e-01,\n",
       "                   6.2398e-02,  3.4736e-01,  7.0093e-02, -5.7558e-02, -2.1203e-02,\n",
       "                  -2.5252e-01,  2.7447e-01, -1.0566e-01,  1.7434e-01, -3.7688e-02,\n",
       "                  -7.4467e-02, -1.2911e-01, -1.3306e-01,  2.7510e-02, -5.6549e-02]],\n",
       "                device='cuda:0')), ('model.connections.0.weight', tensor([[ 0.0181, -0.0497,  0.0698,  ..., -0.0733, -0.1181, -0.0214],\n",
       "                 [-0.1282,  0.0849,  0.0612,  ...,  0.1069,  0.0642,  0.0851],\n",
       "                 [ 0.0766, -0.0678,  0.0126,  ..., -0.0633, -0.0745,  0.1380],\n",
       "                 ...,\n",
       "                 [-0.0956,  0.0446, -0.3496,  ..., -0.0371, -0.0880,  0.0062],\n",
       "                 [-0.1153,  0.1401, -0.1214,  ..., -0.0858,  0.1070,  0.0052],\n",
       "                 [-0.0610, -0.0474, -0.0783,  ...,  0.0514,  0.1071, -0.1160]],\n",
       "                device='cuda:0')), ('model.connections.0.w_mask', tensor([[False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 ...,\n",
       "                 [False, False,  True,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False]], device='cuda:0')), ('model.connections.1.weight', tensor([[-0.0294, -0.0377,  0.0187,  ..., -0.0010,  0.0312,  0.0750],\n",
       "                 [-0.1303,  0.0347, -0.0068,  ..., -0.0355, -0.0797, -0.0006],\n",
       "                 [-0.1057, -0.1160,  0.0933,  ...,  0.0844, -0.1097, -0.1016],\n",
       "                 ...,\n",
       "                 [ 0.0568,  0.0738, -0.0092,  ..., -0.0709, -0.0654,  0.0015],\n",
       "                 [-0.0637, -0.1338,  0.1118,  ...,  0.1348, -0.0521, -0.0304],\n",
       "                 [-0.0813,  0.1206, -0.0814,  ...,  0.1085, -0.0992, -0.0892]],\n",
       "                device='cuda:0')), ('model.connections.1.w_mask', tensor([[False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 ...,\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False],\n",
       "                 [False, False, False,  ..., False, False, False]], device='cuda:0')), ('scores.0_cell_weight_hh_l0', tensor([[ 0.0758,  0.0800, -0.0525,  ..., -0.0918, -0.0775, -0.0221],\n",
       "                 [-0.0641,  0.1069, -0.0697,  ..., -0.1218, -0.0244, -0.0581],\n",
       "                 [-0.0834,  0.0308,  0.0345,  ..., -0.0262,  0.1010,  0.0757],\n",
       "                 ...,\n",
       "                 [ 0.0391, -0.0838, -0.1057,  ...,  0.0769, -0.0563,  0.0427],\n",
       "                 [-0.0680, -0.0117,  0.1064,  ...,  0.1197,  0.0202, -0.0272],\n",
       "                 [-0.0466, -0.0124, -0.0718,  ..., -0.0405, -0.0601,  0.0230]],\n",
       "                device='cuda:0')), ('scores.0_readout_weight', tensor([[ 0.0856,  0.0123,  0.0060, -0.0062, -0.0467,  0.0361, -0.0203,  0.0776,\n",
       "                   0.0156,  0.0842, -0.0934, -0.0718,  0.0538, -0.1209,  0.1018,  0.0522,\n",
       "                  -0.0693, -0.1083,  0.1269, -0.0758,  0.1004, -0.1303, -0.0051,  0.0363,\n",
       "                   0.0902, -0.0481, -0.0598,  0.0611, -0.0590,  0.0960, -0.0831, -0.0455,\n",
       "                  -0.1155,  0.0913,  0.0643, -0.0847,  0.1132,  0.0468, -0.0363,  0.0487,\n",
       "                  -0.1165, -0.1070,  0.0985, -0.0735,  0.0663,  0.0895, -0.0342, -0.0333,\n",
       "                  -0.0229, -0.1068],\n",
       "                 [-0.0604,  0.0037, -0.0388, -0.0065, -0.0230,  0.0447, -0.0153, -0.0131,\n",
       "                   0.0724,  0.0378,  0.0669, -0.0756,  0.0986,  0.1161,  0.0514,  0.0253,\n",
       "                  -0.0632,  0.0707, -0.0155,  0.0736,  0.0023,  0.0334, -0.1143, -0.0193,\n",
       "                  -0.0031,  0.0799, -0.0640, -0.0466,  0.1020, -0.0677,  0.0976,  0.1016,\n",
       "                  -0.0630, -0.1095,  0.0982,  0.0809,  0.0137,  0.0443, -0.0499, -0.0148,\n",
       "                  -0.0757,  0.0431, -0.0154, -0.0347, -0.1178, -0.0466, -0.1023, -0.1280,\n",
       "                   0.1154,  0.0185]], device='cuda:0')), ('scores.1_cell_weight_hh_l0', tensor([[-0.0194, -0.0545,  0.1008,  ...,  0.0502, -0.1037,  0.0532],\n",
       "                 [-0.0658,  0.1256,  0.0575,  ..., -0.0393,  0.0882,  0.1230],\n",
       "                 [-0.0833, -0.0333,  0.0697,  ...,  0.0332, -0.0644,  0.0651],\n",
       "                 ...,\n",
       "                 [ 0.0291,  0.0558, -0.0282,  ...,  0.1046,  0.0555, -0.0057],\n",
       "                 [ 0.1287,  0.0683,  0.0830,  ..., -0.0238, -0.0558,  0.0936],\n",
       "                 [-0.1254, -0.0374,  0.1099,  ..., -0.1006, -0.1064,  0.0242]],\n",
       "                device='cuda:0')), ('scores.1_readout_weight', tensor([[ 1.8973, -0.0599, -0.1656,  1.0172, -0.9405,  0.0417, -0.1469,  2.1724,\n",
       "                  -0.3694,  0.0540, -1.1038,  0.3791, -0.3347,  0.0598, -0.0549,  1.3905,\n",
       "                  -0.0564, -0.5220, -1.1242,  2.0751,  1.2846,  0.4216, -0.3729, -0.1757,\n",
       "                  -0.9267, -0.1125, -0.8259, -0.3593,  0.0899, -0.0531, -0.2087,  0.9208,\n",
       "                   0.2355, -0.2000, -1.0004, -0.1186,  1.2248, -0.1193, -0.0501, -0.0266,\n",
       "                  -0.6642, -0.2281,  0.7643, -0.3064, -0.1145,  0.1397, -0.0330,  0.4519,\n",
       "                   0.1553, -0.0213],\n",
       "                 [ 1.7231, -0.1289,  0.2127,  0.3899, -0.4500, -0.1597, -0.0459,  1.9464,\n",
       "                  -0.0208,  0.7985, -1.1600, -0.0202, -0.2048,  0.2500, -0.0048,  1.9374,\n",
       "                  -0.1141, -0.4321, -1.1342,  1.6954,  1.6040, -0.7184,  0.1638,  0.3157,\n",
       "                  -0.4407,  0.2153, -0.4706,  0.4066,  0.0039, -1.1091, -0.3237,  0.1852,\n",
       "                   0.2659,  0.1217, -0.8353,  0.1081,  2.2237,  0.0513,  0.0216, -0.0851,\n",
       "                  -1.8077, -1.4863,  0.6155, -0.4797, -0.0482, -0.1169,  0.0160,  0.3908,\n",
       "                   0.1635,  0.1086]], device='cuda:0'))])                                                                                                                                  ],\n",
       "        dtype=object)],\n",
       " 'sparsities': array([[0.1, 0.1]])}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_and_get_mask_metric(community, 0.1, loaders, n_tests=1, n_epochs=1, symbols=True, use_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = 1. \n",
    "min_acc = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditional_loop(test_acc, min_acc):\n",
    "    condition = test_acc >= min_acc\n",
    "    print(condition)\n",
    "    while condition :\n",
    "        yield"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05d01965f97943fa930bb5a924b0f5b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "pbar = tqdm(total=100)\n",
    "while test_acc > min_acc : \n",
    "    pbar.update(1)\n",
    "    pbar.set_description(f'For Mask of Sparsity {0.1}, Acc is {test_acc}')\n",
    "    test_acc *= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6258567a8b3643b58e7a13536e7b825c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pbar = tqdm(conditional_loop(test_acc, min_acc))\n",
    "for _ in pbar : \n",
    "    pbar.set_description(f'For Mask of Sparsity {0.1}, Acc is {test_acc}')\n",
    "    test_acc *= 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.5e-323"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('community')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c46eabf39b4d4e6cb6668853226ee702b3f0cb279968f228c052b13b97983d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
