{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Self Contained Model of the Funcspec Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import EMNIST\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm as tqdm_n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.data.datasets import get_datasets_symbols\n",
    "from community.common.utils import plot_grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 256\n",
    "n_classes = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data: 100%|██████████| 30000/30000 [00:03<00:00, 8296.28it/s]\n",
      "Generating Data: 100%|██████████| 30000/30000 [00:03<00:00, 9228.73it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data: 100%|██████████| 5000/5000 [00:00<00:00, 7668.67it/s]\n",
      "Generating Data: 100%|██████████| 5000/5000 [00:00<00:00, 8857.22it/s]\n"
     ]
    }
   ],
   "source": [
    "data_config = {'data_size' : (30000, 5000),\n",
    "                                'nb_steps' : 50,\n",
    "                                'n_symbols' : n_classes - 1,\n",
    "                                'symbol_size' : 5,\n",
    "                                'input_size' : 30,\n",
    "                                'static' : False                         \n",
    "        \n",
    "    }\n",
    "loaders, datasets = get_datasets_symbols(data_config, batch_size, use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_target(target, task) : \n",
    "    try :\n",
    "        task = int(task)\n",
    "        new_target = target[:, task]\n",
    "    except ValueError : \n",
    "\n",
    "        if task == 'parity': \n",
    "            new_target = parity_task(target)\n",
    "        elif task == 'count' : \n",
    "            new_target = symbol_count(target)\n",
    "        else : \n",
    "            raise NotImplementedError\n",
    "\n",
    "    return new_target.type(torch.LongTensor).to(target.device)\n",
    "\n",
    "def parity_task(target) : \n",
    "\n",
    "    parity = 1 - target.sum(-1)%2\n",
    "    parity_target = torch.where(parity.bool(), target[:, 0], target[:, 1])\n",
    "    return parity_target\n",
    "\n",
    "def new_parity_task(target) : \n",
    "    parity = 1 - target.sum(-1)%2\n",
    "    equal = (target[:, 0].eq(target[:, 1]))\n",
    "    parity_target = torch.where(parity.bool(), target[:, 0], target[:, 1])\n",
    "    parity_target = torch.where(equal, torch.full_like(parity_target, n_classes), parity_target)\n",
    "\n",
    "    return parity_target\n",
    "\n",
    "def process_data(data, nb_steps=None, flatten=True, symbols=True, device=device) : \n",
    "    if symbols : data =  data.permute(2, 1, 0, 3, 4)\n",
    "    if flatten : data = data.flatten(start_dim=-2) \n",
    "    if nb_steps : data = torch.stack([data for _ in range(nb_steps)], 1)\n",
    "    \n",
    "    return data.float().to(device)\n",
    "    \n",
    "\n",
    "def get_data(temporal=False, task=None, flatten=True, device=device) : \n",
    "    data, target = next(iter(loaders[0]))\n",
    "    print(data.shape)\n",
    "    data = process_data(data, flatten=flatten, nb_steps=2 if temporal else None)\n",
    "    if task : target = get_task_target(target, task)\n",
    "\n",
    "    return data, target.float().to(device)\n",
    "\n",
    "\n",
    "def symbol_count(target) : \n",
    "    new_target = torch.where(target.argmax(-1).bool(), target[:, 1], target[:, 0])\n",
    "    new_target[target[:, 0] == target[:, 1]] = 0\n",
    "    return new_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothStep(torch.autograd.Function):\n",
    "    '''\n",
    "    Modified from: https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html\n",
    "    '''\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(aux, x, thr=0):\n",
    "        aux.save_for_backward(x)\n",
    "        return (x >=thr).type(x.dtype)\n",
    "\n",
    "    def backward(aux, grad_output):\n",
    "        # grad_input = grad_output.clone()\n",
    "        input, = aux.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input <= -.5] = 0\n",
    "        grad_input[input > .5] = 0\n",
    "        return grad_input\n",
    "    \n",
    "smooth_step = SmoothStep().apply\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements \n",
    "    the surrogate gradient. By subclassing torch.autograd.Function, \n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid \n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "    \n",
    "    scale = 100.0 # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, thr=0):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which \n",
    "        we need to later backpropagate our error signals. To achieve this we use the \n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = -torch.ones_like(input)\n",
    "        out[input > thr] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the \n",
    "        surrogate gradient of the loss with respect to the input. \n",
    "        Here we use the normalized negative part of a fast sigmoid \n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input/(SurrGradSpike.scale*torch.abs(input)+1.0)**2\n",
    "        return grad\n",
    "    \n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "super_spike  = SurrGradSpike.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent(nn.Module) : \n",
    "\n",
    "    def __init__(self, dims, use_conv=False) : \n",
    "        super().__init__()\n",
    "        if use_conv : \n",
    "            S, W, F = 1, input_size, symbol_size\n",
    "            P = int(((S-1)*W-S+F)/2)\n",
    "            print(F, S, P)\n",
    "            self.conv = nn.Sequential(nn.Conv2d(1, 1, F, S, P), nn.Flatten())\n",
    "        else : \n",
    "            self.conv = None\n",
    "\n",
    "        self.use_bottleneck = False\n",
    "        self.dims = dims\n",
    "\n",
    "        self.cell = nn.RNN(dims[0], dims[1], 1, bias=False, batch_first=False)\n",
    "        self.readout = nn.Linear(dims[1], dims[2], bias=False)\n",
    "\n",
    "    def forward(self, input, state=None, connections=0) : \n",
    "\n",
    "        if self.conv : \n",
    "            input = self.conv(input)\n",
    "\n",
    "        if len(input.shape ) < 3 : \n",
    "            input = input.unsqueeze(0)\n",
    "\n",
    "        if state is None : \n",
    "            out, h = self.cell(input)\n",
    "        else : \n",
    "            h = state + connections\n",
    "            out, h = self.cell(input, h)\n",
    "\n",
    "        out = self.readout(out[0])\n",
    "\n",
    "        return out, h\n",
    "\n",
    "class Connection(nn.Linear) : \n",
    "    def __init__(self, dims, p, binarize=False) : \n",
    "\n",
    "        super().__init__(dims[0], dims[1], bias=False)\n",
    "\n",
    "        self.sparsity = p\n",
    "        n_in, n_out = dims\n",
    "        self.nb_non_zero = int(p*n_in*n_out)\n",
    "        w_mask = np.zeros((n_in, n_out),dtype=bool)\n",
    "        ind_in, ind_out = np.unravel_index(np.random.choice(np.arange(n_in*n_out), self.nb_non_zero, replace=False), (n_in, n_out))\n",
    "        w_mask[ind_in,ind_out] = True\n",
    "        w_mask = torch.tensor(w_mask)\n",
    "        self.register_buffer('w_mask', w_mask)\n",
    "        self.binarize = binarize\n",
    "\n",
    "        assert w_mask.sum() == self.nb_non_zero, f'Number of nonzero connection is {w_mask.sum()}, expected {self.nb_non_zero}'\n",
    "\n",
    "    def forward(self, input) : \n",
    "        out = F.linear(input, self.weight*self.w_mask)\n",
    "        assert (out != 0).float().sum(-1).max() <= self.nb_non_zero, f'{(out != 0).float().sum(-1).max()} non zero connections !'\n",
    "        if self.binarize  : \n",
    "            out = super_spike(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Ensemble(nn.Module) : \n",
    "    def __init__(self, dims, p, use_conv=False, binary_con=False) : \n",
    "\n",
    "        super().__init__()\n",
    "        self.n_in, self.n_hid, self.n_out = dims\n",
    "        self.agents = nn.ModuleList([Agent(dims, use_conv) for _ in range(2)])[::-1]\n",
    "        self.connections = nn.ModuleList([Connection([dims[1]]*2, p, binary_con) for _ in range(2)])\n",
    "        self.is_community = True\n",
    "\n",
    "    def forward(self, input): \n",
    "\n",
    "        states, outputs, conns = [None for _ in range(2)], [[] for _ in range(2)], [None for _ in range(2)]\n",
    "        \n",
    "        for t, t_input in enumerate(input) :\n",
    "            for ag, agent in enumerate(self.agents) : \n",
    "                \n",
    "                ag_input = t_input[ag]\n",
    "                \n",
    "                if t>0 : \n",
    "                    input_connect = self.connections[1-ag](states[1-ag])\n",
    "                else : \n",
    "                    input_connect = 0\n",
    "                \n",
    "                out, h = agent(ag_input, states[ag], input_connect)\n",
    "\n",
    "\n",
    "                states[ag] = h\n",
    "                outputs[ag].append(out)\n",
    "                conns[ag] = input_connect\n",
    "\n",
    "        outputs = torch.stack([torch.stack(o) for o in outputs], 1)\n",
    "        states = torch.stack(states, 1)[0]\n",
    "        conns = torch.stack(conns, 1)[0]\n",
    "\n",
    "        #print((outputs[-1][1] == outputs[-1][1]).all())\n",
    "\n",
    "        return outputs, [states], conns\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision(outputs, decision_params, target=None) : \n",
    "    temporal_decision, agent_decision = decision_params\n",
    "\n",
    "    if temporal_decision == 'last' : \n",
    "        outputs = outputs[-1]\n",
    "\n",
    "    else : \n",
    "        raise NotImplementedError\n",
    "\n",
    "    try : \n",
    "        deciding_ags = int(agent_decision)\n",
    "        outputs = outputs[deciding_ags]\n",
    "        deciding_ags = torch.ones(outputs.shape[0])*deciding_ags\n",
    "        return outputs, deciding_ags\n",
    "\n",
    "    except ValueError : \n",
    "\n",
    "        if agent_decision == 'loss' :\n",
    "            assert target is not None, 'Provide target for min loss decision'\n",
    "            loss, min_idxs = torch.stack([F.cross_entropy(out, target, reduction='none') for out in outputs]).min(0)\n",
    "            min_idxs = min_idxs.unsqueeze(-1).expand_as(outputs[0])\n",
    "            outputs = torch.where(~min_idxs.bool(), outputs[0], outputs[1])\n",
    "            deciding_ags = min_idxs[..., 0]\n",
    "            return outputs, deciding_ags\n",
    "\n",
    "        elif agent_decision == 'max' : \n",
    "            device = outputs.device\n",
    "            n_agents = outputs.shape[0]\n",
    "            max_out = lambda i : torch.max(outputs[i,...], axis=-1)\n",
    "            _, deciding_ags = torch.max(torch.stack([max_out(i)[0] for i in range(n_agents)]), axis=0)\n",
    "            mask_1 = deciding_ags.unsqueeze(0).unsqueeze(-1).expand_as(outputs)\n",
    "            mask_2 = torch.einsum('b, bcx -> bcx', torch.arange(n_agents).to(device), torch.ones_like(outputs))\n",
    "            mask = (mask_1 == mask_2)\n",
    "\n",
    "            return (outputs*mask).sum(0), deciding_ags\n",
    "\n",
    "        else : \n",
    "            raise NotImplementedError\n",
    "\n",
    "def check_grad(model, task_id = '0') : \n",
    "    for n, p in model.named_parameters() : \n",
    "        if 'k_params' in n or 'all_scores' in n : \n",
    "            if task_id in n : \n",
    "                return check_ind_grad(n, p)\n",
    "        else : \n",
    "            check_ind_grad(n, p)\n",
    "\n",
    "def check_ind_grad(n, p) : \n",
    "    if p.grad is not None : \n",
    "        if (p.grad == 0).all() : \n",
    "            ''\n",
    "            print(f'{n}, Zero Grad')\n",
    "        #else : print(f'{n} : {p.grad}')\n",
    "    elif p.requires_grad : \n",
    "        ''\n",
    "        print(f'{n}, None Grad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = [data_config['input_size']**2, 50, n_classes]\n",
    "sparsity = 1 * 1/dims[1]**2\n",
    "\n",
    "use_conv = False\n",
    "binary_connections = True\n",
    "\n",
    "community = Ensemble(dims, sparsity, use_conv, binary_connections).to(device)\n",
    "optimizer = torch.optim.Adam(community.parameters(), lr=1e-3)\n",
    "\n",
    "#summary(community.agents[0], (1, input_size, input_size) if use_conv else (1, input_size**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 50, 2, 30, 30])\n",
      "(tensor([-1.,  1.], device='cuda:0', grad_fn=<Unique2Backward0>), tensor([25396,   204], device='cuda:0'))\n"
     ]
    }
   ],
   "source": [
    "data, target = get_data(flatten=True, temporal=False, device=device)\n",
    "out, states, conns = community(data)\n",
    "if binary_connections : print(conns.unique(return_counts=True))\n",
    "#symbol_count(target).unique(return_counts=True), (symbol_count(target) == target[:, 0]).unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "community.agents[0].use_bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7219d3c938b84110a6055e960a25e1ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Correlation Metric Trials:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from community.funcspec.bottleneck import readout_retrain\n",
    "corrs = get_pearson_metrics(community,  loaders, symbols=True, use_tqdm=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.02759257, -0.03359341],\n",
       "       [-0.04030826,  0.01669626]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs.mean(-1).mean(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make_dot(out[-1][1], dict(community.named_parameters())).render('graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c56e007ab7948d8aebc711a55b42160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "decision_params = ('last', 'max') # Change to '0', '1' or 'loss'\n",
    "task = 'count'\n",
    "\n",
    "pbar = tqdm_n(range(n_epochs))\n",
    "descs = np.full((2), '', dtype=object)\n",
    "\n",
    "check_gradients = False\n",
    "\n",
    "train, test = True, True\n",
    "\n",
    "early_stop = True\n",
    "\n",
    "#train_loader, test_loader = loaders if not symbols else symbol_loaders()\n",
    "#subset = len(train_loader) if not symbols else 100000\n",
    "\n",
    "for epoch in pbar : \n",
    "    train_loader, test_loader = loaders\n",
    "\n",
    "    if train : \n",
    "            \n",
    "        # Training\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(train_loader) : \n",
    "            \n",
    "            data = process_data(data, None, True, True, device)\n",
    "            target = get_task_target(target, task).to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs, states, conns = community(data)\n",
    "            #print((outputs[-1][0] == outputs[-1][1]).all())\n",
    "            output, deciding_ags = get_decision(outputs, decision_params, target)\n",
    "\n",
    "            loss = F.cross_entropy(output, target)\n",
    "            loss.backward()\n",
    "\n",
    "            if check_gradients : \n",
    "                zero_grads = np.array([((p.grad == 0).all()).cpu().data.item() for p in community.parameters() if p.grad is not None])\n",
    "                none_grads = np.array([p.grad is None for p in community.parameters()])\n",
    "                zero_params = np.array(list(dict(community.named_parameters()).keys()), dtype=object)[~none_grads][zero_grads]\n",
    "                none_params = np.array(list(dict(community.named_parameters()).keys()), dtype=object)[none_grads]\n",
    "\n",
    "                print(f'Zero params : {zero_params}')\n",
    "                print(f'None Params : {none_params}')\n",
    "                \n",
    "            optimizer.step()\n",
    "\n",
    "            pred = output.argmax(dim=-1, keepdim=True)\n",
    "            correct = pred.eq(target.view_as(pred)).sum().cpu().data.item()\n",
    "            acc = (correct / target.numel())\n",
    "\n",
    "            descs[0] = str('Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.3f}, Accuracy: {}%'.format(\n",
    "                            epoch, batch_idx  * batch_size, len(train_loader.dataset),\n",
    "                            100. * batch_idx / len(train_loader), loss.item(),\n",
    "                            (np.round(100*a) for a in acc) if type(acc) is list else np.round(100*acc))\n",
    "                            )\n",
    "\n",
    "            pbar.set_description((descs.sum()))\n",
    "\n",
    "    if test : \n",
    "        acc = []\n",
    "        for batch_idx, (data, target) in enumerate(test_loader) : \n",
    "            \n",
    "            data = process_data(data, None, True, True, device)\n",
    "            target = get_task_target(target, task).to(device)\n",
    "\n",
    "            outputs, states, conns = community(data)\n",
    "            #print((outputs[-1][0] == outputs[-1][1]).all())\n",
    "            output, deciding_ags = get_decision(outputs, decision_params, target)\n",
    "\n",
    "            loss = F.cross_entropy(output, target)\n",
    "\n",
    "            pred = output.argmax(dim=-1, keepdim=True)\n",
    "            correct = pred.eq(target.view_as(pred)).sum().cpu().data.item()\n",
    "            acc += [correct / target.numel()]\n",
    "\n",
    "        acc = np.mean(acc)\n",
    "        \n",
    "        descs[1] = str('| Test : Loss: {:.3f}, Accuracy: {}%'.format(\n",
    "                        loss.item(),\n",
    "                        (np.round(100*a) for a in acc) if type(acc) is list else np.round(100*acc))\n",
    "                        )\n",
    "\n",
    "        pbar.set_description((descs.sum()))\n",
    "\n",
    "    if acc > 0.95 and early_stop: \n",
    "            break\n",
    "            #continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_conv : \n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "    for ag, ax in zip(community.agents, axs) : \n",
    "        im = ax.imshow((ag.conv[0].weight.data.cpu().numpy()[0, 0]))\n",
    "\n",
    "#plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8218eb00",
   "metadata": {},
   "source": [
    "## Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfe8de",
   "metadata": {},
   "source": [
    "### Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c7ecd0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'use_symbols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000024vscode-remote?line=2'>3</a>\u001b[0m nonzero_idxs \u001b[39m=\u001b[39m [c\u001b[39m.\u001b[39mw_mask\u001b[39m.\u001b[39mnonzero()[:, \u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m community\u001b[39m.\u001b[39mconnections]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000024vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m data, target \u001b[39min\u001b[39;00m loaders[\u001b[39m1\u001b[39m] : \n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000024vscode-remote?line=6'>7</a>\u001b[0m     data, target \u001b[39m=\u001b[39m process_data(data, nb_steps \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m use_symbols \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39mTrue\u001b[39;00m, use_symbols, device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000024vscode-remote?line=7'>8</a>\u001b[0m     out, states, conns \u001b[39m=\u001b[39m community(data\u001b[39m.\u001b[39mto(device))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000024vscode-remote?line=9'>10</a>\u001b[0m     \u001b[39m#conns[-1][0].count_nonzero(dim=0)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000024vscode-remote?line=10'>11</a>\u001b[0m     \u001b[39m#torch.stack([conns[-1][i].count_nonzero(dim=0).max() for i in range(2)])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#ch0000024vscode-remote?line=11'>12</a>\u001b[0m     \u001b[39m#sums.append(torch.tensor([[conns[-1][i][target[:, i] == t].sum() for t in range(4)] for i in range(2)]))\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'use_symbols' is not defined"
     ]
    }
   ],
   "source": [
    "community.to(device)\n",
    "sums = []\n",
    "nonzero_idxs = [c.w_mask.nonzero()[:, 0] for c in community.connections]\n",
    "\n",
    "for data, target in loaders[1] : \n",
    "    \n",
    "    data, target = process_data(data, nb_steps if not use_symbols else None, True, use_symbols, device), target.to(device)\n",
    "    out, states, conns = community(data.to(device))\n",
    "    \n",
    "    #conns[-1][0].count_nonzero(dim=0)\n",
    "    #torch.stack([conns[-1][i].count_nonzero(dim=0).max() for i in range(2)])\n",
    "    #sums.append(torch.tensor([[conns[-1][i][target[:, i] == t].sum() for t in range(4)] for i in range(2)]))\n",
    "    sums.append(torch.stack([torch.stack([conns[i][target[:, 1-i] == t][:, nonzero_idxs[1-i]].sum(0) for t in range(n_classes)]) for i in range(2)]))\n",
    "\n",
    "sums = torch.stack(sums).cpu().data.numpy().mean(0)[..., 0]\n",
    "ax = sns.heatmap(sums, cmap=\"inferno\", annot=sums.round(1).astype(str), annot_kws={'fontsize': 16}, fmt='s')\n",
    "ax.set_xlabel('Digit Received by other agent')\n",
    "ax.set_ylabel('Connection received by agent : ')\n",
    "ax.set_title('Average of connections received by agents')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318caa3",
   "metadata": {},
   "source": [
    " ### Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859de41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7938/1162496303.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  mask = target.eq(torch.tensor(t)).all(axis=1)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "get_all_targets = lambda : torch.cat([t for _, t in loaders[1]])\n",
    "\n",
    "all_targets = get_all_targets()\n",
    "\n",
    "uniques = all_targets.unique(dim=0).cpu()\n",
    "decision_means = torch.zeros(len(uniques))\n",
    "\n",
    "community.to('cpu')\n",
    "for b_idx, (data, target) in enumerate(loaders[1]) : \n",
    "    \n",
    "    data, target = process_data(data, nb_steps if not use_symbols else None, True, use_symbols, 'cpu'), target.to('cpu')\n",
    "    t_target = get_task_target(target, task).cpu()\n",
    "    output, *_ = community(data)\n",
    "    output, decision_ags = get_decision(output, decision_params, target=t_target)\n",
    "\n",
    "    for i, t in enumerate(uniques) : \n",
    "        mask = target.eq(torch.tensor(t)).all(axis=1)\n",
    "        decision_means[i] += decision_ags[mask].float().cpu().sum()/mask.sum()\n",
    "decision_means /= b_idx +1\n",
    "\n",
    "digits_in = lambda d1, d2 : (torch.tensor([d1, d2]) == uniques).all(1).any()\n",
    "digits_idx = lambda d1, d2 : (torch.tensor([d1, d2]) == uniques).all(1).float().argmax()\n",
    "decisions = np.zeros((n_classes, n_classes))\n",
    "targets = np.zeros((n_classes, n_classes), dtype=object)\n",
    "\n",
    "for d1 in range(n_classes) : \n",
    "    for d2 in range(n_classes) : \n",
    "        if digits_in(d1, d2) : \n",
    "            decisions[d1, d2] = decision_means[digits_idx(d1, d2)]\n",
    "            targets[d1, d2] = str(get_task_target(uniques, task)[digits_idx(d1, d2)].cpu().data.item())\n",
    "        else : \n",
    "            decisions[d1, d2] = -0.1\n",
    "            targets[d1, d2] = 'X'\n",
    "            \n",
    "ax = sns.heatmap(decisions, cmap=\"inferno\", annot=targets, annot_kws={'fontsize': 16}, fmt='s')\n",
    "ax.set_title('Average decison-making agent for all targets')\n",
    "\n",
    "ax.set_xlabel('Digit received by Agent 1')\n",
    "ax.set_ylabel('Digit received by Agent 0')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('community')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c46eabf39b4d4e6cb6668853226ee702b3f0cb279968f228c052b13b97983d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
