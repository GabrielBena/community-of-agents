{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Self Contained Model of the Funcspec Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import EMNIST\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm as tqdm_n\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torchviz import make_dot\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "from copy import copy, deepcopy\n",
    "from tqdm.notebook import tqdm, trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\n",
    "    \"xkcd:cloudy blue\",\n",
    "    \"xkcd:gray\",\n",
    "    \"xkcd:orange\",\n",
    "    \"xkcd:dark seafoam\",\n",
    "    \"xkcd:purple\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.data.datasets import get_datasets_symbols\n",
    "from community.utils.plotting import plot_grid, create_gifs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data: 100%|██████████| 30000/30000 [00:00<00:00, 47381.47it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Data: 100%|██████████| 5000/5000 [00:00<00:00, 51802.76it/s]\n"
     ]
    }
   ],
   "source": [
    "n_classes = 45\n",
    "\n",
    "data_config = {\n",
    "    \"data_size\": (30000, 5000),\n",
    "    \"nb_steps\": 50,\n",
    "    \"n_symbols\": n_classes - 1,\n",
    "    \"symbol_type\": \"mod_5\",\n",
    "    \"input_size\": 60,\n",
    "    \"static\": True,\n",
    "    \"double_data\": False,\n",
    "    'n_diff_symbols' : 3\n",
    "}\n",
    "\n",
    "if data_config[\"static\"]:\n",
    "    data_config[\"nb_steps\"] = 6\n",
    "    data_config[\"data_size\"] = [d for d in data_config[\"data_size\"]]\n",
    "\n",
    "if not data_config[\"double_data\"]:\n",
    "    n_classes //= 2\n",
    "\n",
    "n_bits = np.ceil(np.log2(n_classes)).astype(int)\n",
    "loaders, datasets = get_datasets_symbols(data_config, batch_size, use_cuda, plot=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 6, 60, 60])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gb21/.conda/envs/community/lib/python3.10/site-packages/matplotlib/text.py:1223: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if s != self._text:\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x1440 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if False:\n",
    "    datasets[0].regenerate = False\n",
    "    data, target = get_data(flatten=False)\n",
    "    print(data.shape)\n",
    "    create_gifs(\n",
    "        data[:, 0, :, 0, :, :],\n",
    "        target.T,\n",
    "        \"symbols\",\n",
    "        data_config[\"input_size\"],\n",
    "        \"none\",\n",
    "        data_config[\"double_data\"],\n",
    "    )\n",
    "\n",
    "#data, target = datasets[1].data[:2]\n",
    "data, target = next(iter(loaders[0]))\n",
    "print(data.shape)\n",
    "fig, axs = plt.subplots(10, 1, figsize=(20, 20))\n",
    "for d, ax in enumerate(axs) : \n",
    "    \n",
    "    try : \n",
    "        ax.imshow(data[d, 0, 0, 0].cpu())\n",
    "    except (IndexError): \n",
    "        ax.imshow(data[d, 0, 0].cpu())\n",
    "    except TypeError : \n",
    "        ax.imshow(data[d, 0].cpu())\n",
    "\n",
    "    ax.set_title(target[d].cpu().numpy())\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks / Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_task_target(target, task):\n",
    "\n",
    "    if type(task) is list : \n",
    "        try : \n",
    "            return torch.stack([get_task_target(target, t) for t in task])\n",
    "        except : \n",
    "            return [get_task_target(target, t) for t in task]\n",
    "\n",
    "    else : \n",
    "            \n",
    "        tasks = task.split(\"_\")\n",
    "        try:\n",
    "            task = int(tasks[-1])\n",
    "            target = target[:, task]\n",
    "            return target\n",
    "        except ValueError:\n",
    "            \"continue\"\n",
    "\n",
    "        if \"parity\" in tasks:\n",
    "            target = parity_task(target)\n",
    "        elif \"count\" in tasks:\n",
    "            if \"max\" in tasks:\n",
    "                target = symbol_count(target)\n",
    "            elif \"equal\" in tasks:\n",
    "                target = symbol_count(target) != 0\n",
    "        elif \"nonzero\" in tasks:\n",
    "            target = target > 0\n",
    "        elif \"none\" in tasks:\n",
    "            target = target.T\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return target.type(torch.LongTensor).to(target.device)\n",
    "\n",
    "from community.data.tasks import get_task_target\n",
    "\n",
    "\n",
    "def parity_task(target):\n",
    "\n",
    "    parity = 1 - target.sum(-1) % 2\n",
    "    parity_target = torch.where(parity.bool(), target[:, 0], target[:, 1])\n",
    "    return parity_target\n",
    "\n",
    "\n",
    "def new_parity_task(target):\n",
    "    parity = 1 - target.sum(-1) % 2\n",
    "    equal = target[:, 0].eq(target[:, 1])\n",
    "    parity_target = torch.where(parity.bool(), target[:, 0], target[:, 1])\n",
    "    parity_target = torch.where(\n",
    "        equal, torch.full_like(parity_target, n_classes), parity_target\n",
    "    )\n",
    "\n",
    "    return parity_target\n",
    "\n",
    "\n",
    "def process_data(data, flatten=True, device=device):\n",
    "\n",
    "    if len(data.shape) == 5:\n",
    "        data = data.permute(1, 2, 0, 3, 4)\n",
    "    else:\n",
    "        data = data.transpose(0, 1)\n",
    "    if flatten:\n",
    "        data = data.flatten(start_dim=-2)\n",
    "    else:\n",
    "        data = data.unsqueeze(-3)\n",
    "\n",
    "    return data.float().to(device)\n",
    "\n",
    "\n",
    "def get_data(task=None, flatten=True, device=device):\n",
    "    data, target = next(iter(loaders[0]))\n",
    "    print(data.shape)\n",
    "    data = process_data(data, flatten=flatten)\n",
    "    if task:\n",
    "        target = get_task_target(target, task)\n",
    "\n",
    "    return data, target.float().to(device)\n",
    "\n",
    "\n",
    "def symbol_count(target):\n",
    "    new_target = torch.where(target.argmax(-1).bool(), target[:, 1], target[:, 0])\n",
    "    new_target[target[:, 0] == target[:, 1]] = 0\n",
    "    return new_target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0c7f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"sum\"\n",
    "get_all_targets = lambda: torch.cat([t for _, t in loaders[1]])\n",
    "\n",
    "if False:\n",
    "\n",
    "    all_targets = get_all_targets()\n",
    "    uniques, unique_counts = all_targets.unique(dim=0, return_counts=True)\n",
    "    task_t = get_task_target(all_targets, task)\n",
    "    task_t.unique(dim=0, return_counts=True), (all_targets[:, 0] == task_t).unique(\n",
    "        dim=0, return_counts=True\n",
    "    ), (all_targets[:, 1] == task_t).unique(dim=0, return_counts=True)\n",
    "    digits_in = lambda d1, d2: (torch.tensor([d1, d2]) == uniques).all(1).any()\n",
    "    digits_idx = (\n",
    "        lambda d1, d2: (torch.tensor([d1, d2]) == uniques).all(1).float().argmax()\n",
    "    )\n",
    "    counts = np.zeros((n_classes + 1, n_classes + 1))\n",
    "    targets = np.zeros((n_classes + 1, n_classes + 1), dtype=object)\n",
    "\n",
    "    for d1 in range(n_classes):\n",
    "        counts[d1, -1] = (\n",
    "            (all_targets[:, 0] == task_t)[all_targets[:, 0] == d1]\n",
    "        ).sum()  # unique_counts[(uniques == d1)[:, 0]].sum()\n",
    "        targets[d1, -1] = str(counts[d1, -1])\n",
    "        for d2 in range(n_classes):\n",
    "            if digits_in(d1, d2):\n",
    "                counts[d1, d2] = unique_counts[digits_idx(d1, d2)]\n",
    "                targets[\n",
    "                    d1, d2\n",
    "                ] = f\"{get_task_target(uniques, task)[digits_idx(d1, d2)].cpu().data.item()} | {unique_counts[digits_idx(d1, d2)]}\"\n",
    "            else:\n",
    "                counts[d1, d2] = -0.1\n",
    "                targets[d1, d2] = \"X\"\n",
    "            counts[-1, d2] = (\n",
    "                (all_targets[:, 1] == task_t)[all_targets[:, 1] == d2]\n",
    "            ).sum()  # unique_counts[(uniques == d2)[:, 1]].sum()\n",
    "            targets[-1, d2] = str(counts[-1, d2])\n",
    "\n",
    "    counts[-1, -1] = unique_counts.sum().cpu().data.item()\n",
    "    try:\n",
    "        d0_count = (all_targets[:, 0] == task_t).unique(dim=0, return_counts=True)[1][1]\n",
    "        print((all_targets[:, 0] == task_t).unique(dim=0, return_counts=True))\n",
    "    except IndexError:\n",
    "        d0_count = 0\n",
    "    try:\n",
    "        d1_count = (all_targets[:, 1] == task_t).unique(dim=0, return_counts=True)[1][1]\n",
    "    except IndexError:\n",
    "        d1_count = 0\n",
    "\n",
    "    targets[-1, -1] = str(f\"D0 : {d0_count} \\n\" f\"D1 : {d1_count}\")\n",
    "\n",
    "    plt.figure(figsize=(5, 5), dpi=150)\n",
    "    ax = sns.heatmap(\n",
    "        counts, cmap=\"inferno\", annot=targets, annot_kws={\"fontsize\": 7}, fmt=\"s\"\n",
    "    )\n",
    "    ax.set_title(\"Number of examples and global targets\")\n",
    "\n",
    "    ax.set_xlabel(\"Digit received by Agent 1\")\n",
    "    ax.set_ylabel(\"Digit received by Agent 0\")\n",
    "    ax.set_xticklabels([str(i) for i in range(n_classes)] + [\"dig=global\"], fontsize=7)\n",
    "    ax.set_yticklabels([str(i) for i in range(n_classes)] + [\"dig=global\"], fontsize=7)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # loaders, datasets = get_datasets_symbols(data_config, batch_size, use_cuda)\n",
    "    all_targets = get_all_targets()\n",
    "    task_t = get_task_target(all_targets, task)\n",
    "    all_targets[:, 1].unique(return_counts=True), task_t.unique(return_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothStep(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Modified from: https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(aux, x, thr=0):\n",
    "        aux.save_for_backward(x)\n",
    "        return (x >= thr).type(x.dtype)\n",
    "\n",
    "    def backward(aux, grad_output):\n",
    "        # grad_input = grad_output.clone()\n",
    "        (input,) = aux.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad_input[input <= -0.5] = 0\n",
    "        grad_input[input > 0.5] = 0\n",
    "        return grad_input\n",
    "\n",
    "\n",
    "smooth_step = SmoothStep().apply\n",
    "sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "class SurrGradSpike(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Here we implement our spiking nonlinearity which also implements\n",
    "    the surrogate gradient. By subclassing torch.autograd.Function,\n",
    "    we will be able to use all of PyTorch's autograd functionality.\n",
    "    Here we use the normalized negative part of a fast sigmoid\n",
    "    as this was done in Zenke & Ganguli (2018).\n",
    "    \"\"\"\n",
    "\n",
    "    scale = 100.0  # controls steepness of surrogate gradient\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, input, thr=0):\n",
    "        \"\"\"\n",
    "        In the forward pass we compute a step function of the input Tensor\n",
    "        and return it. ctx is a context object that we use to stash information which\n",
    "        we need to later backpropagate our error signals. To achieve this we use the\n",
    "        ctx.save_for_backward method.\n",
    "        \"\"\"\n",
    "        ctx.save_for_backward(input)\n",
    "        out = -torch.ones_like(input)\n",
    "        out[input > thr] = 1.0\n",
    "        return out\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        \"\"\"\n",
    "        In the backward pass we receive a Tensor we need to compute the\n",
    "        surrogate gradient of the loss with respect to the input.\n",
    "        Here we use the normalized negative part of a fast sigmoid\n",
    "        as this was done in Zenke & Ganguli (2018).\n",
    "        \"\"\"\n",
    "        (input,) = ctx.saved_tensors\n",
    "        grad_input = grad_output.clone()\n",
    "        grad = grad_input / (SurrGradSpike.scale * torch.abs(input) + 1.0) ** 2\n",
    "        return grad\n",
    "\n",
    "\n",
    "# here we overwrite our naive spike function by the \"SurrGradSpike\" nonlinearity which implements a surrogate gradient\n",
    "super_spike = SurrGradSpike.apply\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_padding(S, K, W):\n",
    "    return int(((S - 1) * W - S + K) / 2)\n",
    "\n",
    "\n",
    "def init_weights(net, scale):\n",
    "    for n, p in net.named_parameters():\n",
    "        try:\n",
    "            torch.nn.init.xavier_normal_(p)\n",
    "        except ValueError:\n",
    "            \"continue\"\n",
    "        p.data *= scale\n",
    "\n",
    "\n",
    "class Agent(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dims,\n",
    "        use_conv=False,\n",
    "        use_bottleneck=False,\n",
    "        dropout=0.0,\n",
    "        w_scale=1.0,\n",
    "        n_layers=1,\n",
    "        n_readouts=1,\n",
    "        linear_ag=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dims = dims\n",
    "        assert not (use_conv and linear_ag)\n",
    "\n",
    "        self.linear_ag = linear_ag\n",
    "\n",
    "        if not linear_ag:\n",
    "\n",
    "            if use_conv:\n",
    "                # K, S, W = 3, 1, data_config['input_size']\n",
    "                # P = get_padding(S, K, W)\n",
    "                convs = []\n",
    "                channels = [1, 4]\n",
    "                kernels = [5, 3]\n",
    "                pools = [2, 2]\n",
    "                feature_height, feature_width = [data_config[\"input_size\"]] * 2\n",
    "                for i, (K, P, n_in, n_out) in enumerate(\n",
    "                    zip(kernels, pools, channels[:-1], channels[1:])\n",
    "                ):\n",
    "\n",
    "                    convs.append(nn.Conv2d(n_in, n_out, K, 1, padding=\"same\"))\n",
    "                    convs.append(nn.MaxPool2d(P))\n",
    "                    convs.append(nn.ReLU())\n",
    "                    if dropout > 0.0:\n",
    "                        convs.append(nn.Dropout(dropout))\n",
    "\n",
    "                convs.append(nn.Flatten())\n",
    "                self.conv = nn.Sequential(*convs)\n",
    "\n",
    "                # self.conv = nn.Sequential(nn.Conv2d(1, 8, K, S, P), nn.Flatten())\n",
    "\n",
    "                dummy_data = torch.zeros(\n",
    "                    [1] + [channels[0]] + [data_config[\"input_size\"]] * 2\n",
    "                )\n",
    "                dummy_out = self.conv(dummy_data)\n",
    "                print(dummy_out.shape)\n",
    "                self.dims[0] = dummy_out.shape[-1]\n",
    "            else:\n",
    "                self.conv = None\n",
    "\n",
    "            self.use_bottleneck = use_bottleneck\n",
    "            self.linear_ag = linear_ag\n",
    "\n",
    "            self.n_layers = n_layers\n",
    "            if data_config[\"static\"]:\n",
    "                self.cell = nn.RNN(\n",
    "                    dims[0], dims[1], n_layers, bias=False, batch_first=False\n",
    "                )\n",
    "            else:\n",
    "                self.cell = nn.GRU(\n",
    "                    dims[0], dims[1], n_layers, bias=False, batch_first=False\n",
    "                )\n",
    "\n",
    "            self.dropout = nn.Dropout(dropout) if dropout > 0 else None\n",
    "\n",
    "            n_in_readout = dims[1]\n",
    "\n",
    "            if use_bottleneck:\n",
    "                n_bot = 5\n",
    "                self.bottleneck = nn.Sequential(\n",
    "                    nn.Linear(n_in_readout, n_bot, bias=False), nn.ReLU()\n",
    "                )\n",
    "                self.bottleneck.out_features = n_bot\n",
    "                readout = [nn.Linear(n_bot, dims[-1], bias=False)]\n",
    "            else:\n",
    "                # self.readout = nn.Sequential(nn.Linear(n_in_readout, dims[-1], bias=False), nn.Softmax())\n",
    "                readout = [nn.Linear(n_in_readout, dims[-1], bias=False)]\n",
    "\n",
    "        else:\n",
    "            readout = [nn.Linear(dims[0], dims[-1], bias=False)]\n",
    "\n",
    "        self.dual_readout = n_readouts > 1\n",
    "        if self.dual_readout:\n",
    "            readout.extend([deepcopy(readout[0]) for _ in range(n_readouts - 1)])\n",
    "\n",
    "        self.readout = nn.ModuleList(readout)\n",
    "\n",
    "        init_weights(self, w_scale)\n",
    "\n",
    "        # self.readout = nn.Linear(dims[1], dims[2], bias=False)\n",
    "\n",
    "    def forward(self, input, state=None, connections=0):\n",
    "\n",
    "        if not self.linear_ag:\n",
    "\n",
    "            if self.conv:\n",
    "                input = self.conv(input)\n",
    "\n",
    "            if len(input.shape) < 3:\n",
    "                input = input.unsqueeze(0)\n",
    "\n",
    "            if state is None:\n",
    "                out, h = self.cell(input)\n",
    "            else:\n",
    "                if self.n_layers > 1:\n",
    "                    h = torch.stack([state[0] + connections, *state[1:]])\n",
    "                else:\n",
    "                    h = state + connections\n",
    "                out, h = self.cell(input, h)\n",
    "\n",
    "            if self.dropout:\n",
    "                out = self.dropout(out)\n",
    "\n",
    "            if self.use_bottleneck:\n",
    "                out = self.bottleneck(out[0]).unsqueeze(0)\n",
    "\n",
    "        else:\n",
    "\n",
    "            out = input.unsqueeze(0)\n",
    "            h = torch.tensor([0])\n",
    "\n",
    "        out = torch.stack([r(out[0]) for r in self.readout])\n",
    "\n",
    "        return out, h\n",
    "\n",
    "\n",
    "class Connection(nn.Linear):\n",
    "    def __init__(self, dims, p, binarize=False, w_scale=1.0):\n",
    "\n",
    "        super().__init__(dims[0], dims[1], bias=False)\n",
    "\n",
    "        init_weights(self, w_scale)\n",
    "\n",
    "        self.sparsity = p\n",
    "        n_in, n_out = dims\n",
    "        self.nb_non_zero = int(p * n_in * n_out)\n",
    "\n",
    "        w_mask = self.init_mask(n_in, n_out)\n",
    "\n",
    "        self.register_buffer(\"w_mask\", w_mask)\n",
    "        self.binarize = binarize\n",
    "\n",
    "        assert (\n",
    "            w_mask.sum() == self.nb_non_zero\n",
    "        ), f\"Number of nonzero connection is {w_mask.sum()}, expected {self.nb_non_zero}\"\n",
    "\n",
    "    def init_mask(self, n_in, n_out):\n",
    "        w_mask = np.zeros((n_in, n_out), dtype=bool)\n",
    "        ind_in, ind_out = np.unravel_index(\n",
    "            np.random.choice(np.arange(n_in * n_out), self.nb_non_zero, replace=False),\n",
    "            (n_in, n_out),\n",
    "        )\n",
    "        if (\n",
    "            len(np.unique(ind_in)) == 1 or len(np.unique(ind_in)) == 1\n",
    "        ) and self.nb_non_zero > 1:\n",
    "            return self.init_mask(n_in, n_out)\n",
    "        else:\n",
    "            print(ind_in, ind_out)\n",
    "            w_mask[ind_in, ind_out] = True\n",
    "            w_mask = torch.tensor(w_mask)\n",
    "            return w_mask\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = F.linear(input, self.weight * self.w_mask)\n",
    "        if self.nb_non_zero > 0:\n",
    "            assert (out != 0).float().sum(\n",
    "                -1\n",
    "            ).max() <= self.nb_non_zero, f\"{(out != 0).float().sum(-1).max()} non zero connections, expected {self.nb_non_zero} !\"\n",
    "        if self.binarize:\n",
    "            out = super_spike(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "def binary_conn(target, ag):\n",
    "    encoding = []\n",
    "    encoded_target = target[:, ag].clone().detach()\n",
    "    for d in range(n_bits - 1, -1, -1):\n",
    "        encoding.append(torch.div(encoded_target, 2**d, rounding_mode=\"floor\"))\n",
    "        encoded_target -= (\n",
    "            torch.div(encoded_target, 2**d, rounding_mode=\"floor\") * 2**d\n",
    "        )\n",
    "    return torch.stack(encoding, -1)\n",
    "\n",
    "\n",
    "class DroupoutMasked(nn.Dropout):\n",
    "    # Dropout mask that can't put nonzero connections at zero\n",
    "    def __init__(self, conn_mask, p: float = 0.5, inplace: bool = False) -> None:\n",
    "        super().__init__(p, inplace)\n",
    "\n",
    "        # True where connections are nonzero else False\n",
    "        self.register_buffer(\"conn_mask\", conn_mask)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_temp = super().forward(x)\n",
    "\n",
    "        conn_mask = self.conn_mask.expand_as(x_temp)\n",
    "\n",
    "        # Final dropout mask, True where not dropped or connections are nonzero\n",
    "        mask = (x_temp != 0) | (conn_mask)\n",
    "\n",
    "        return x * mask\n",
    "\n",
    "\n",
    "class Ensemble(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dims,\n",
    "        n_agents,\n",
    "        p,\n",
    "        use_conv=False,\n",
    "        binary_con=False,\n",
    "        use_bottleneck=False,\n",
    "        n_readouts=[1, 1],\n",
    "        common_readout=False,\n",
    "        dropout=0.0,\n",
    "        w_scale=0.1,\n",
    "        n_layers=1,\n",
    "        linear_ag=False,\n",
    "        single_input=True,\n",
    "    ):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.n_in, self.n_hid, self.n_out = dims\n",
    "        self.n_layers = n_layers\n",
    "        self.n_agents = n_agents\n",
    "\n",
    "        self.connections = nn.ModuleDict(\n",
    "            {\n",
    "                f\"{i}-{j}\": Connection([dims[1]] * 2, p, binary_con, w_scale)\n",
    "                for i in range(n_agents)\n",
    "                for j in range(n_agents)\n",
    "                if j != i\n",
    "            }\n",
    "        )\n",
    "\n",
    "        self.conn_masks = [c.w_mask for c in self.connections.values()]\n",
    "\n",
    "        self.single_input = single_input\n",
    "\n",
    "        self.nonzero_received = [torch.where(c)[0] for c in self.conn_masks][::-1]\n",
    "        self.nonzero_sent = [torch.where(c)[1] for c in self.conn_masks]\n",
    "\n",
    "        self.agents = nn.ModuleList(\n",
    "            [\n",
    "                Agent(\n",
    "                    dims,\n",
    "                    use_conv,\n",
    "                    use_bottleneck,\n",
    "                    dropout,\n",
    "                    w_scale,\n",
    "                    n_layers,\n",
    "                    n_readouts[0],\n",
    "                    linear_ag,\n",
    "                )\n",
    "                for i in range(n_agents)\n",
    "            ]\n",
    "        )[::-1]\n",
    "        self.is_community = True\n",
    "\n",
    "        self.use_common_readout = common_readout\n",
    "        self.dual_readout = n_readouts[1] > 1\n",
    "\n",
    "        if common_readout:\n",
    "            readout = [nn.Linear(n_agents * dims[-2], dims[-1])]\n",
    "            \n",
    "            if self.dual_readout:\n",
    "                readout.extend([deepcopy(readout[0]) for _ in range(n_readouts[1] - 1)])\n",
    "            self.common_readout = nn.ModuleList(readout)\n",
    "\n",
    "    def forward(self, input, forced_conns=None):\n",
    "\n",
    "        tag = lambda ag1, ag2: f\"{ag1}-{ag2}\"\n",
    "\n",
    "        self.min_t_comms = data_config[\"nb_steps\"] // 2\n",
    "\n",
    "        states, conns = [[None] for _ in range(self.n_agents)], [[] for _ in range(self.n_agents)]\n",
    "        outputs = [[] for _ in range(self.n_agents)] if not self.use_common_readout else []\n",
    "\n",
    "        for t, t_input in enumerate(input):\n",
    "            for ag, agent in enumerate(self.agents):\n",
    "\n",
    "                ag_input = t_input[ag] if not self.single_input else t_input.clone()\n",
    "\n",
    "                if t >= self.min_t_comms:\n",
    "                    if forced_conns is not None:\n",
    "                        input_connect = forced_conns[:, ag]\n",
    "                    else:\n",
    "                        try:\n",
    "                            input_connect = torch.stack(\n",
    "                                [\n",
    "                                    self.connections[tag(ag, ag2)](states[ag2][-1][-1])\n",
    "                                    for ag2 in range(len(self.agents))\n",
    "                                    if ag2 != ag\n",
    "                                ]\n",
    "                            ).sum(0)\n",
    "\n",
    "                        except (IndexError, RuntimeError) as e:  # Linear ag\n",
    "                            input_connect = torch.tensor([0])\n",
    "                else:\n",
    "                    input_connect = 0\n",
    "\n",
    "                try:\n",
    "                    out, h = agent(ag_input, states[ag][-1], input_connect)\n",
    "                except IndexError:  # Linear agent\n",
    "                    out, h = agent(ag_input)\n",
    "\n",
    "                states[ag].append(h)\n",
    "                if not self.use_common_readout:\n",
    "                    outputs[ag].append(out)\n",
    "                conns[ag].append(input_connect)\n",
    "\n",
    "            if self.use_common_readout:\n",
    "                out = torch.stack(\n",
    "                    [\n",
    "                        r(torch.cat([s[-1] for s in states], -1))[0]\n",
    "                        for r in self.common_readout\n",
    "                    ]\n",
    "                )\n",
    "                outputs.append(out)\n",
    "\n",
    "        if not self.use_common_readout:\n",
    "            outputs = torch.stack([torch.stack(o) for o in outputs], 1)\n",
    "        else:\n",
    "            outputs = torch.stack(outputs, 0)\n",
    "\n",
    "        if self.n_layers > 1:\n",
    "            states = torch.stack(\n",
    "                [torch.stack([s[-1] for s in st[1:]]) for st in states], 1\n",
    "            )\n",
    "        else:\n",
    "            states = torch.stack([torch.cat(s[1:]) for s in states], 1)\n",
    "\n",
    "        conns = torch.stack([torch.stack(c[self.min_t_comms :]) for c in conns], 1)\n",
    "\n",
    "        # print((outputs[-1][1] == outputs[-1][1]).all())\n",
    "\n",
    "        return outputs.squeeze(), states, conns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decision(outputs, decision_params, target=None):\n",
    "    temporal_decision, agent_decision = decision_params\n",
    "\n",
    "    if temporal_decision == \"last\":\n",
    "        outputs = outputs[-1]\n",
    "    elif temporal_decision == \"sum\":\n",
    "        outputs = outputs.sum(0)\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "    agent_decisions = agent_decision.split(\"_\")\n",
    "\n",
    "    try:\n",
    "        deciding_ags = int(agent_decisions[-1])\n",
    "        outputs = outputs[deciding_ags]\n",
    "        deciding_ags = torch.ones(outputs.shape[0]) * deciding_ags\n",
    "        return outputs, deciding_ags\n",
    "\n",
    "    except ValueError:\n",
    "\n",
    "        if agent_decision == \"max\":\n",
    "            device = outputs.device\n",
    "            n_agents = outputs.shape[0]\n",
    "            max_out = lambda i: torch.max(outputs[i, ...], axis=-1)\n",
    "            _, deciding_ags = torch.max(\n",
    "                torch.stack([max_out(i)[0] for i in range(n_agents)]), axis=0\n",
    "            )\n",
    "            mask_1 = deciding_ags.unsqueeze(0).unsqueeze(-1).expand_as(outputs)\n",
    "            mask_2 = torch.einsum(\n",
    "                \"b, bcx -> bcx\",\n",
    "                torch.arange(n_agents).to(device),\n",
    "                torch.ones_like(outputs),\n",
    "            )\n",
    "            mask = mask_1 == mask_2\n",
    "\n",
    "            return (outputs * mask).sum(0), deciding_ags\n",
    "\n",
    "        elif agent_decision == \"both\":\n",
    "            return outputs, None\n",
    "\n",
    "        elif \"sum\" in agent_decision:\n",
    "            return outputs.sum(0), None\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "\n",
    "from community.common.decision import get_decision\n",
    "\n",
    "\n",
    "def check_grad(model, task_id=\"0\"):\n",
    "    for n, p in model.named_parameters():\n",
    "        if \"k_params\" in n or \"all_scores\" in n:\n",
    "            if task_id in n:\n",
    "                return check_ind_grad(n, p)\n",
    "        else:\n",
    "            check_ind_grad(n, p)\n",
    "\n",
    "\n",
    "def check_ind_grad(n, p):\n",
    "    if p.grad is not None:\n",
    "        if (p.grad == 0).all():\n",
    "            \"\"\"\"\"\"\n",
    "            print(f\"{n}, Zero Grad\")\n",
    "        # else : print(f'{n} : {p.grad}')\n",
    "    elif p.requires_grad:\n",
    "        \"\"\"\"\"\"\n",
    "        print(f\"{n}, None Grad\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3]\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "[] []\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "               RNN-1  [[-1, 1, 10], [-1, 1, 10]]               0\n",
      "            Linear-2                   [-1, 15]             150\n",
      "================================================================\n",
      "Total params: 150\n",
      "Trainable params: 150\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.01\n",
      "----------------------------------------------------------------\n",
      "torch.Size([256, 6, 60, 60])\n",
      "torch.Size([6, 3, 256, 15])\n"
     ]
    }
   ],
   "source": [
    "#task = [[\"0\", \"1\"], ['1', '2'], ['2', '0']]\n",
    "#task = [str(d) for d in range(data_config['n_diff_symbols'])]\n",
    "\n",
    "task = 'all'\n",
    "\n",
    "decision_params = (\"last\", \"all\")  # Change to '0', '1' or 'loss'\n",
    "\n",
    "dims = [\n",
    "    data_config[\"input_size\"] ** 2,\n",
    "    10,\n",
    "    n_classes if not (task == \"equal_count\" or task == \"nonzero\") else 2,\n",
    "]\n",
    "\n",
    "n_agents = data_config['n_diff_symbols']\n",
    "n_layers = 1\n",
    "sparsity = 0.  # 1* 1/dims[1]**2\n",
    "\n",
    "use_conv = False\n",
    "binary_connections = False\n",
    "use_bottleneck = False\n",
    "\n",
    "n_readouts = [1, 1] # agent readouts x common readout\n",
    "common_readout = True\n",
    "single_input=True\n",
    "\n",
    "\n",
    "if type(task) is list : \n",
    "    n_readouts[common_readout] = len(task[0])\n",
    "elif task in ['all', 'none', 'both'] : \n",
    "    n_readouts[common_readout] = data_config['n_diff_symbols']\n",
    "    print(n_readouts)\n",
    "\n",
    "linear_ags = False\n",
    "\n",
    "community = Ensemble(\n",
    "    dims,\n",
    "    n_agents,\n",
    "    sparsity,\n",
    "    use_conv,\n",
    "    binary_connections,\n",
    "    use_bottleneck,\n",
    "    n_readouts,\n",
    "    common_readout,\n",
    "    n_layers=1,\n",
    "    linear_ag=linear_ags,\n",
    "    single_input=single_input\n",
    "    \n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(community.parameters(), lr=1e-3)\n",
    "\n",
    "gamma = 0.95  # ** (1/len(loaders[0]))\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma, verbose=False)\n",
    "# if use_conv :\n",
    "# summary(community.agents[0].conv, (1, data_config['input_size'], data_config['input_size']) if use_conv else (1, data_config['input_size']**2))\n",
    "\n",
    "summary(\n",
    "    community.agents[0],\n",
    "    (1, data_config[\"input_size\"], data_config[\"input_size\"])\n",
    "    if use_conv\n",
    "    else (1, data_config[\"input_size\"] ** 2),\n",
    ")\n",
    "\n",
    "# plot_confusion_mat(community)\n",
    "data, target = get_data(flatten=not use_conv, device=device)\n",
    "# print(community)\n",
    "# print(data.shape)\n",
    "\n",
    "out, states, fconns = community(data)\n",
    "if binary_connections:\n",
    "    print(fconns[-1].unique(return_counts=True))\n",
    "print(out.shape)\n",
    "# symbol_count(target).unique(return_counts=True), (symbol_count(target) == target[:, 0]).unique(return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = (\n",
    "    f'saves/network_{n_classes}{\"_non\"*(1 - data_config[\"static\"])}_static_p={sparsity}'\n",
    ")\n",
    "# torch.save(community.state_dict(), file_path)\n",
    "# community.load_state_dict(torch.load(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Stop exec before training\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Stop exec before training\n",
    "raise StopIteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From wandb/package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.funcspec.single_model_loop import (\n",
    "    init_and_train,\n",
    "    train_and_compute_metrics,\n",
    "    train_community,\n",
    ")\n",
    "from community.utils.configs import get_training_dict\n",
    "import yaml\n",
    "from yaml.loader import SafeLoader\n",
    "\n",
    "with open(\"../../latest_config.yml\", \"r\") as config_file:\n",
    "    config = yaml.load(config_file, SafeLoader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config[\"task\"] = \"both\"\n",
    "config[\"training\"][\"decision_params\"] = (\"last\", \"both\")\n",
    "\n",
    "config[\"model_params\"][\"common_readout\"] = False\n",
    "\n",
    "if config[\"task\"] == \"both\":\n",
    "    if config[\"model_params\"][\"common_readout\"]:\n",
    "        config[\"model_params\"][\"common_dual_readout\"] = True\n",
    "        config[\"model_params\"][\"agents_params\"][\"ag_dual_readout\"] = False\n",
    "    else:\n",
    "        config[\"model_params\"][\"common_dual_readout\"] = False\n",
    "        config[\"model_params\"][\"agents_params\"][\"ag_dual_readout\"] = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_community(\n",
    "    community,\n",
    "    *loaders,\n",
    "    optimizers=[optimizer, None],\n",
    "    config=get_training_dict(config),\n",
    "    show_all_acc=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "818d2a9ce9804e65bcf3417b3bcb9985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from community.common.training import get_loss\n",
    "\n",
    "n_epochs = 50\n",
    "\n",
    "pbar = tqdm_n(range(n_epochs))\n",
    "descs = np.full((2), \"\", dtype=object)\n",
    "\n",
    "check_gradients = False\n",
    "train, test = True, True\n",
    "early_stop = True\n",
    "test_cheat = False\n",
    "\n",
    "force_connections = False\n",
    "\n",
    "best_acc = 0\n",
    "acc_hist, loss_hist = [[] for _ in range(2)], [[] for _ in range(2)]\n",
    "\n",
    "\n",
    "for epoch in pbar:\n",
    "    train_loader, test_loader = loaders\n",
    "\n",
    "    if train:\n",
    "        community.train()\n",
    "        # Training\n",
    "        losses, accs = [], []\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "\n",
    "            data = process_data(data, not use_conv, device)\n",
    "            t_target, target = get_task_target(target, task).to(device), target.to(\n",
    "                device\n",
    "            )\n",
    "\n",
    "            if test_cheat:\n",
    "                data[:, 0] = data[:, 1]\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if force_connections:\n",
    "                conns = fconns[-1].detach().unsqueeze(0)\n",
    "                for ag in range(2):\n",
    "                    conns[:, ag, :, community.nonzero_received[ag]] = binary_conn(\n",
    "                        target, 1 - ag\n",
    "                    ).float()\n",
    "                conns[conns == 0] = -1\n",
    "            else:\n",
    "                conns = None\n",
    "\n",
    "            outputs, states, conns = community(data, conns)\n",
    "            # print((outputs[-1][0] == outputs[-1][1]).all())\n",
    "\n",
    "            output, deciding_ags = get_decision(outputs, *decision_params)\n",
    "\n",
    "            loss, t_target, output = get_loss(output, t_target)\n",
    "            # t_masks = [(target == t ).all(1) for t in target.unique(dim=0)]\n",
    "            # t_masks = [(target == t).any(1)]\n",
    "            # masks = [(t_target == 0)*t_masks[0], (t_target == 3)*t_masks[0]]\n",
    "            # factors = torch.ones(len(t_masks))\n",
    "            # factors[0] *= 1\n",
    "            # loss = torch.stack([loss[m].mean()*f for m, f in zip(t_masks, factors)]).mean()\n",
    "\n",
    "            loss.backward()\n",
    "            losses.append(loss.cpu().data.item())\n",
    "\n",
    "            if check_gradients:\n",
    "                zero_grads = np.array(\n",
    "                    [\n",
    "                        ((p.grad == 0).all()).cpu().data.item()\n",
    "                        for p in community.parameters()\n",
    "                        if p.grad is not None\n",
    "                    ]\n",
    "                )\n",
    "                none_grads = np.array([p.grad is None for p in community.parameters()])\n",
    "                zero_params = np.array(\n",
    "                    list(dict(community.named_parameters()).keys()), dtype=object\n",
    "                )[~none_grads][zero_grads]\n",
    "                none_params = np.array(\n",
    "                    list(dict(community.named_parameters()).keys()), dtype=object\n",
    "                )[none_grads]\n",
    "\n",
    "                print(f\"Zero params : {zero_params}\")\n",
    "                print(f\"None Params : {none_params}\")\n",
    "\n",
    "            optimizer.step()  # , scheduler.step()\n",
    "\n",
    "            pred = output.argmax(dim=-1)\n",
    "            correct = pred.eq(t_target.view_as(pred))\n",
    "            acc = (\n",
    "                (correct.sum(-1) * np.prod(t_target.shape[:-1]) / t_target.numel())\n",
    "                .cpu()\n",
    "                .data.numpy()\n",
    "            )\n",
    "\n",
    "            # acc = [(correct[m].sum()/m.sum()).cpu().data.numpy() for m in masks]\n",
    "\n",
    "            accs.append(acc)\n",
    "\n",
    "            descs[0] = str(\n",
    "                \"Train Epoch: {} [{}/{} ({:.0f}%)] Loss: {:.3f}, Accuracy: {}%, Decider : {}\".format(\n",
    "                    epoch,\n",
    "                    batch_idx * batch_size,\n",
    "                    len(train_loader.dataset),\n",
    "                    100.0 * batch_idx / len(train_loader),\n",
    "                    loss.item(),\n",
    "                    ([np.round(100 * a) for a in acc])\n",
    "                    if type(acc) is list\n",
    "                    else np.round(100 * acc),\n",
    "                    np.round(deciding_ags.float().mean().cpu().data.item(), 1)\n",
    "                    if deciding_ags is not None\n",
    "                    else \"none\",\n",
    "                )\n",
    "            )\n",
    "\n",
    "            pbar.set_description((descs.sum()))\n",
    "\n",
    "        loss_hist[0].append(np.mean(losses))\n",
    "        acc_hist[0].append(np.mean(accs))\n",
    "\n",
    "    if test:\n",
    "        losses, accs = [], []\n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "\n",
    "            data, target = process_data(data, not use_conv, device), target.to(device)\n",
    "            if test_cheat:\n",
    "                data[:, 0] = data[:, 1]\n",
    "            t_target = get_task_target(target, task).to(device)\n",
    "\n",
    "            if force_connections:\n",
    "                conns = fconns[-1].clone().detach().unsqueeze(0)\n",
    "                for ag in range(2):\n",
    "                    conns[:, ag, :, community.nonzero_received[ag]] = binary_conn(\n",
    "                        target, 1 - ag\n",
    "                    ).float()\n",
    "                conns[conns == 0] = -1\n",
    "            else:\n",
    "                conns = None\n",
    "\n",
    "            outputs, states, _ = community(data, conns)\n",
    "            # print((outputs[-1][0] == outputs[-1][1]).all())\n",
    "            output, deciding_ags = get_decision(outputs, *decision_params, t_target)\n",
    "\n",
    "            loss, t_target, output = get_loss(output, t_target)\n",
    "            loss = loss.mean()\n",
    "            losses.append(loss.cpu().data.item())\n",
    "\n",
    "            pred = output.argmax(dim=-1, keepdim=True)\n",
    "            correct = pred.eq(t_target.view_as(pred)).sum().cpu().data.item()\n",
    "            accs.append(correct / t_target.numel())\n",
    "\n",
    "        acc = np.mean(accs)\n",
    "\n",
    "        loss_hist[1].append(np.mean(losses))\n",
    "        acc_hist[1].append(np.mean(accs))\n",
    "\n",
    "        descs[1] = str(\n",
    "            \"| Test : Loss: {:.3f}, Accuracy: {}%\".format(\n",
    "                loss.item(),\n",
    "                (np.round(100 * a) for a in acc)\n",
    "                if type(acc) is list\n",
    "                else np.round(100 * acc),\n",
    "            )\n",
    "        )\n",
    "\n",
    "        pbar.set_description((descs.sum()))\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_model = deepcopy(community)\n",
    "        best_acc = acc\n",
    "\n",
    "    if acc > 0.95 and early_stop:\n",
    "        break\n",
    "\n",
    "decision_params = (\"last\", \"both\")  # Change to '0', '1' or 'loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, constrained_layout=True, figsize=(12, 8))\n",
    "for metric, m_axs, m_name in zip([loss_hist, acc_hist], axs, [\"Loss\", \"Acc\"]):\n",
    "    for trial, ax, t_name in zip([0, 1], m_axs, [\"Train\", \"Test\"]):\n",
    "        ax.plot(metric[trial])\n",
    "        ax.set_title(f\"{t_name} {m_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(best_model.state_dict(), f'saves/network_{task}_{n_classes}{\"_non\"*(1 - data_config[\"static\"])}_static_p={sparsity}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_params = (\"last\", \"0\")\n",
    "\n",
    "\n",
    "def plot_accuracy_matrix(model, test_loader):\n",
    "\n",
    "    accs = []\n",
    "    targets, t_targets = [], []\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "\n",
    "        data, target = process_data(data, not use_conv, device), target.to(device)\n",
    "        t_target = get_task_target(target, task).to(device)\n",
    "\n",
    "        if force_connections:\n",
    "            conns = fconns.clone().detach()\n",
    "            for ag in range(2):\n",
    "                conns[:, ag, :, community.nonzero_received[ag]] = binary_conn(\n",
    "                    target, 1 - ag\n",
    "                )\n",
    "            conns[conns == 0] = -1\n",
    "        else:\n",
    "            conns = None\n",
    "\n",
    "        outputs, states, conns = model(data, conns)\n",
    "        # print((outputs[-1][0] == outputs[-1][1]).all())\n",
    "        output, deciding_ags = get_decision(outputs, *decision_params, target)\n",
    "\n",
    "        loss, t_target = get_loss(output, t_target, task)\n",
    "\n",
    "        pred = output.argmax(dim=-1, keepdim=True)\n",
    "        correct = pred.eq(t_target.view_as(pred)).cpu().data\n",
    "        targets.append(target.cpu())\n",
    "        t_targets.append(t_target.cpu())\n",
    "        accs.append(correct)\n",
    "\n",
    "    accs, targets = torch.cat(accs), torch.cat(targets)\n",
    "    n_classes = len(targets.unique())\n",
    "    t_masks = [(targets == t).all(1) for t in targets.unique(dim=0)]\n",
    "    acc_per_target = np.array([accs[m].float().mean() for m in t_masks]).reshape(\n",
    "        n_classes, n_classes\n",
    "    )\n",
    "\n",
    "    # acc_per_target = np.array([[acc_per_target[t1*n_classes + t2].cpu().data.item() for t1 in range(n_classes)] for t2 in range(n_classes)])\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        acc_per_target, cmap=\"inferno\", annot=None, annot_kws={\"fontsize\": 10}, fmt=\"s\"\n",
    "    )\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_accuracy_matrix(best_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_mat(model, test_loader):\n",
    "\n",
    "    accs, preds = [], []\n",
    "    targets, t_targets = [], []\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "\n",
    "        data, target = process_data(data, not use_conv, device), target.to(device)\n",
    "        t_target = get_task_target(target, task).to(device)\n",
    "\n",
    "        outputs, states, conns = model(data)\n",
    "        # print((outputs[-1][0] == outputs[-1][1]).all())\n",
    "        output, deciding_ags = get_decision(outputs, *decision_params, target)\n",
    "\n",
    "        loss, t_target = get_loss(output, t_target, task)\n",
    "        pred = output.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "        correct = pred.eq(t_target.view_as(pred)).cpu().data\n",
    "        targets.append(target.cpu())\n",
    "        t_targets.append(t_target.cpu())\n",
    "        accs.append(correct)\n",
    "        preds.append(pred.cpu())\n",
    "\n",
    "    preds, t_targets = torch.cat(preds), torch.cat(t_targets)\n",
    "\n",
    "    n_classes = len(t_targets.unique())\n",
    "    t_masks = [(t_targets == t) for t in t_targets.unique()]\n",
    "\n",
    "    pred_per_target = [preds[m] for m in t_masks]\n",
    "    n_pred_per_target = np.zeros((n_classes, n_classes))\n",
    "    for t, p in enumerate(pred_per_target):\n",
    "        for (u, c) in zip(*p.unique(return_counts=True)):\n",
    "            n_pred_per_target[t, u] = c\n",
    "\n",
    "    n_pred_per_target /= n_pred_per_target.sum(1)\n",
    "\n",
    "    # acc_per_target = np.array([[acc_per_target[t1*n_classes + t2].cpu().data.item() for t1 in range(n_classes)] for t2 in range(n_classes)])\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "        n_pred_per_target, cmap=\"inferno\", annot_kws={\"fontsize\": 10}, fmt=\"s\"\n",
    "    )\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "    plt.show()\n",
    "\n",
    "    return n_pred_per_target\n",
    "\n",
    "\n",
    "n_pred_per_target = plot_confusion_mat(best_model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9dfe8de",
   "metadata": {},
   "source": [
    "### Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7ecd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "community = best_model\n",
    "community.to(device)\n",
    "nonzero_idxs = community.nonzero_received\n",
    "n_conns = len(nonzero_idxs[0])\n",
    "\n",
    "# for data, target in loaders[1] :\n",
    "data, target = get_data(flatten=not use_conv)\n",
    "\n",
    "# data, target = process_data(data, True, True, device), target.to(device)\n",
    "out, states, conns = best_model(data.to(device))\n",
    "\n",
    "if force_connections:\n",
    "    conns = -torch.ones_like(conns).to(device)\n",
    "    for ag in range(2):\n",
    "        conns[:, ag, :, community.nonzero_received[ag][:n_bits]] = binary_conn(\n",
    "            target, 1 - ag, n_classes\n",
    "        )\n",
    "\n",
    "    conns[conns == 0] = -1\n",
    "\n",
    "# conns[-1][0].count_nonzero(dim=0)\n",
    "# torch.stack([conns[-1][i].count_nonzero(dim=0).max() for i in range(2)])\n",
    "# sums.append(torch.tensor([[conns[-1][i][target[:, i] == t].sum() for t in range(4)] for i in range(2)]))\n",
    "\n",
    "\"\"\"\n",
    "ncols = int(np.sqrt(n_conns))\n",
    "nrows = n_conns // ncols\n",
    "if ncols * nrows < n_conns : \n",
    "    ncols += 1\n",
    "print(nrows, ncols)\n",
    "\"\"\"\n",
    "\n",
    "if data_config[\"static\"]:\n",
    "\n",
    "    sums = torch.tensor(\n",
    "        [\n",
    "            [\n",
    "                conns[-1, ag, target[:, 1 - ag] == t][:, nonzero_idxs[ag]].sum(0)\n",
    "                for t in range(n_classes)\n",
    "            ]\n",
    "            for ag in range(2)\n",
    "        ]\n",
    "    )\n",
    "    if n_conns == 1:\n",
    "        sums = sums.unsqueeze(-1)\n",
    "\n",
    "    if n_classes < 4:\n",
    "\n",
    "        nrows, ncols = 2, n_classes\n",
    "\n",
    "        fig, axs = plt.subplots(\n",
    "            nrows,\n",
    "            ncols,\n",
    "            figsize=(n_classes * (n_conns), 2),\n",
    "            constrained_layout=True,\n",
    "            dpi=100,\n",
    "            sharey=True,\n",
    "        )\n",
    "\n",
    "        for ag, ag_axs in enumerate(axs):\n",
    "            for dig, ax in enumerate(ag_axs):\n",
    "                sum = sums[ag][dig].cpu().data.numpy()\n",
    "                bars = ax.bar(np.arange(len(sum)), sum, color=col)\n",
    "                # ax.set_xticks(np.arange(len(sum)))\n",
    "                # ax.bar_label(bars)\n",
    "                # sns.heatmap(sum, cmap=\"inferno\", annot=sum.round(1).astype(str), annot_kws={'fontsize': 16}, fmt='s', ax=ax)\n",
    "\n",
    "                ax.set_xticks([])\n",
    "                ax.set_xlabel(f\"Digit {dig}\")\n",
    "                if dig == 0:\n",
    "                    ax.set_ylabel(f\"Ag {ag}\")\n",
    "    else:\n",
    "        lines = [\"-\", \"--\"]\n",
    "        fig = plt.figure(constrained_layout=True, figsize=(12, 4), dpi=130)\n",
    "        fig.suptitle(\"Connections Per Classes\")\n",
    "        subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "        nrows, ncols = 1, 1\n",
    "\n",
    "        for ag, subfig in enumerate(subfigs):\n",
    "            subfig.suptitle(f\"Agent {ag}\")\n",
    "            sum = sums[ag]\n",
    "            ax = subfig.subplots(nrows=nrows, ncols=ncols)\n",
    "\n",
    "            [\n",
    "                ax.plot(\n",
    "                    range(len(s)),\n",
    "                    s.cpu().data.numpy(),\n",
    "                    linestyle=lines[c % 2],\n",
    "                    label=f\"Connection {c}\",\n",
    "                )\n",
    "                for c, s in enumerate(sum.T)\n",
    "            ]\n",
    "            ax.set_xlabel(\"Classes\")\n",
    "            ax.legend()\n",
    "            # ax.set_title(f'Agent {i}')\n",
    "\n",
    "else:\n",
    "    nrows, ncols = 1, 1\n",
    "\n",
    "    lines = [\"-\", \"--\"]\n",
    "    fig = plt.figure(constrained_layout=True, figsize=(12, 4), dpi=130)\n",
    "    fig.suptitle(\"Connections Through Time\")\n",
    "    subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "\n",
    "    sums = torch.stack(\n",
    "        [\n",
    "            torch.stack(\n",
    "                [\n",
    "                    community.nonzero_receivedonns[:, i, target[:, 1 - i] == t][\n",
    "                        ..., nonzero_idxs[1 - i]\n",
    "                    ].sum(1)\n",
    "                    for t in range(n_classes)\n",
    "                ]\n",
    "            )\n",
    "            for i in range(2)\n",
    "        ]\n",
    "    )\n",
    "    for ag, subfig in enumerate(subfigs):\n",
    "        subfig.suptitle(f\"Agent {ag}\")\n",
    "\n",
    "        axs = subfig.subplots(nrows=nrows, ncols=ncols)\n",
    "        if n_conns == 1:\n",
    "            axs = np.array([axs])\n",
    "        for i, ax in enumerate(axs.flatten()):\n",
    "            sum = sums.cpu().data.numpy()[ag, ..., i]\n",
    "            for t, s in enumerate(sum):\n",
    "                ax.plot(range(len(s)), s, label=f\"Digit {t}\", linestyle=lines[t % 2])\n",
    "\n",
    "            ax.legend()\n",
    "            ax.set_title(f\"Connection {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(loaders[1]))\n",
    "plot_data = data[:5, -1, :].reshape(-1, 1, 100, 50).cpu().data\n",
    "t_target = get_task_target(target, task)\n",
    "plot_data[..., 50, :] = 0.5\n",
    "plot_grid(\n",
    "    plot_data,\n",
    "    [\n",
    "        f\"Counts : {t.data.numpy()} \\n Target : {t_t.item()}\"\n",
    "        for t, t_t in zip(target, t_target)\n",
    "    ],\n",
    "    figsize=(10, 10),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318caa3",
   "metadata": {},
   "source": [
    "### Decisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4859de41",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_targets = lambda: torch.cat([t for _, t in loaders[1]])\n",
    "\n",
    "all_targets = get_all_targets()\n",
    "\n",
    "uniques = all_targets.unique(dim=0).cpu()\n",
    "decision_means = torch.zeros(len(uniques))\n",
    "\n",
    "community.to(\"cpu\")\n",
    "\n",
    "for b_idx, (data, target) in enumerate(loaders[1]):\n",
    "\n",
    "    data, target = process_data(data, True, True, \"cpu\"), target.to(\"cpu\")\n",
    "    t_target = get_task_target(target, task).cpu()\n",
    "    output, *_ = community(data)\n",
    "    output, decision_ags = get_decision(output, decision_params, target=t_target)\n",
    "\n",
    "    for i, t in enumerate(uniques):\n",
    "        mask = target.eq(torch.tensor(t)).all(axis=1)\n",
    "        if mask.sum() != 0:\n",
    "            decision_means[i] += decision_ags[mask].float().cpu().sum() / mask.sum()\n",
    "\n",
    "decision_means /= b_idx + 1\n",
    "\n",
    "digits_in = lambda d1, d2: (torch.tensor([d1, d2]) == uniques).all(1).any()\n",
    "digits_idx = lambda d1, d2: (torch.tensor([d1, d2]) == uniques).all(1).float().argmax()\n",
    "decisions = np.zeros((n_classes, n_classes))\n",
    "targets = np.zeros((n_classes, n_classes), dtype=object)\n",
    "\n",
    "for d1 in range(n_classes):\n",
    "    for d2 in range(n_classes):\n",
    "        if digits_in(d1, d2):\n",
    "            decisions[d1, d2] = decision_means[digits_idx(d1, d2)]\n",
    "            targets[d1, d2] = str(\n",
    "                get_task_target(uniques, task)[digits_idx(d1, d2)].cpu().data.item()\n",
    "            )\n",
    "        else:\n",
    "            decisions[d1, d2] = -0.1\n",
    "            targets[d1, d2] = \"X\"\n",
    "\n",
    "ax = sns.heatmap(\n",
    "    decisions, cmap=\"inferno\", annot=targets, annot_kws={\"fontsize\": 16}, fmt=\"s\"\n",
    ")\n",
    "ax.set_title(\"Average decison-making agent for all targets\")\n",
    "\n",
    "ax.set_xlabel(\"Digit received by Agent 1\")\n",
    "ax.set_ylabel(\"Digit received by Agent 0\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "community.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "if use_conv:\n",
    "\n",
    "    convs = [\n",
    "        [c for c in ag.conv if type(c) is torch.nn.Conv2d] for ag in community.agents\n",
    "    ]\n",
    "    symbols = datasets[0].symbols[:-1]\n",
    "\n",
    "    corrs = np.array(\n",
    "        [\n",
    "            [\n",
    "                [\n",
    "                    pearsonr(kernel.cpu().data.numpy().flatten(), symbol.flatten())[0]\n",
    "                    for kernel in conv[0].weight[:, 0]\n",
    "                ]\n",
    "                for conv in convs\n",
    "            ]\n",
    "            for symbol in symbols\n",
    "        ]\n",
    "    )  # 2 symbols x 2 convs x n_channels_out\n",
    "\n",
    "    fig = plt.figure(\n",
    "        constrained_layout=True, figsize=((convs[0][0].out_channels + 1) * 2, 5)\n",
    "    )\n",
    "    # fig.suptitle('Conv Weights')\n",
    "\n",
    "    # create 3x1 subfigs\n",
    "    subfigs = fig.subfigures(nrows=len(convs) + 1, ncols=1)\n",
    "    for row, (subfig, conv) in enumerate(zip(subfigs, convs)):\n",
    "        subfig.suptitle(f\"Agent {row}\")\n",
    "\n",
    "        # create 1x3 subplots per subfig\n",
    "        axs = subfig.subplots(nrows=len(conv), ncols=conv[0].out_channels)\n",
    "\n",
    "        for col, ax in enumerate(axs.flatten()):\n",
    "            im = ax.imshow((conv[0].weight.data.cpu().numpy()[col, 0]))\n",
    "            ax.set_title(f\"Conv weight {col} \\n Corr = {corrs[:, row, col].round(1)}\")\n",
    "\n",
    "        cbar = subfig.colorbar(im, ax=axs.ravel().tolist(), shrink=0.95)\n",
    "\n",
    "    axs = subfigs[-1].subplots(nrows=1, ncols=2)\n",
    "    for a, (ax, symb) in enumerate(zip(axs, symbols)):\n",
    "        im = ax.imshow(symb)\n",
    "        ax.set_title(f\"Mean corr to symbol per ag : {corrs[a].mean(-1).round(2)}\")\n",
    "    subfigs[-1].suptitle(\"Symbols to be detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_max = lambda c: (c.max() - c.min()) / c.sum()\n",
    "[diff_max(corr / corr.max()) for corr in corrs.mean(-1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(product(*(convs, symbols))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "convs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcspec Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_metric = lambda c: (c[0] - c[1]) / c.sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.funcspec.correlation import (\n",
    "    v_pearsonr,\n",
    "    get_correlation,\n",
    "    randperm_no_fixed,\n",
    "    get_pearson_metrics,\n",
    "    fixed_information_data,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3077db6cd9a6482aa3806e66323ec3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Correlation Metric Trials:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrs_metrics = get_pearson_metrics(\n",
    "    community, loaders, symbols=True, use_tqdm=True, device=device, double_data=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_corrs': array([[[-0.05548982, -0.0509544 , -0.07486226],\n",
       "         [-0.05551602, -0.06234744, -0.07529901]],\n",
       " \n",
       "        [[-0.09324056, -0.06306177, -0.04610248],\n",
       "         [-0.07569309, -0.08125391, -0.04755315]]]),\n",
       " 'relative_corrs': array([[[ 0.52819626,  1.22879556,  1.08463464],\n",
       "         [ 0.52844561,  1.50354549,  1.09096253]],\n",
       " \n",
       "        [[11.78615417,  0.80254657, -1.67372595],\n",
       "         [ 9.56805062,  1.03406633, -1.72639181]]]),\n",
       " 'base_corrs': array([[-0.10505531, -0.04146695, -0.06902071],\n",
       "        [-0.00791103, -0.07857708,  0.02754482]])}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52819626,  0.52844561],\n",
       "       [11.78615417,  9.56805062]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_metrics['relative_corrs'][..., 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb Cell 58\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m fig, axs \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m, \u001b[39m10\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m ag, ag_axs \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(axs):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m     ag_corrs \u001b[39m=\u001b[39m corrs\u001b[39m.\u001b[39;49mmean(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mmean(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)[:, ag]\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y111sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         t_corrs \u001b[39m=\u001b[39m ag_corrs[t]\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrs = corrs_metrics['mean_corrs'][..., 2]  # agents x timesteps x target\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "for ag, ag_axs in enumerate(axs):\n",
    "    ag_corrs = corrs.mean(-1).mean(-1)[:, ag]\n",
    "    for t in range(2):\n",
    "        t_corrs = ag_corrs[t]\n",
    "        ag_axs[0].bar(range(len(t_corrs)), (-1) ** t * t_corrs, label=f\"Digit {t}\")\n",
    "\n",
    "    diff_corrs = [diff_max(c) for c in ag_corrs.T]\n",
    "    ag_axs[1].bar(range(len(diff_corrs)), diff_corrs)\n",
    "\n",
    "    ag_axs[0].set_title(f\"Correlations for Agent {ag}\")\n",
    "    for ax in ag_axs:\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.set_xticks(range(len(t_corrs)))\n",
    "        ax.set_xticklabels([\"Before Comms\", \"After Comms\"])\n",
    "        ax.legend()\n",
    "    ag_axs[0].set_ylabel(\"Correlation\")\n",
    "    ag_axs[1].set_title(f\"Correlation Diff for Agent {ag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "for ag, ag_axs in enumerate(axs):\n",
    "    ag_corrs = corrs.mean(-1).mean(-1)[:, ag]\n",
    "    for t in range(2):\n",
    "        t_corrs = ag_corrs[t] / base_corrs.mean(-1)[ag]\n",
    "        ag_axs[0].bar(range(len(t_corrs)), (-1) ** t * t_corrs, label=f\"Digit {t}\")\n",
    "\n",
    "    diff_corrs = [diff_max(c) for c in ag_corrs.T]\n",
    "    ag_axs[1].bar(range(len(diff_corrs)), diff_corrs)\n",
    "\n",
    "    ag_axs[0].set_title(f\"Correlations for Agent {ag}\")\n",
    "    for ax in ag_axs:\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.set_xticks(range(len(t_corrs)))\n",
    "        ax.set_xticklabels([\"Before Comms\", \"After Comms\"])\n",
    "        ax.legend()\n",
    "    ag_axs[0].set_ylabel(\"Correlation\")\n",
    "    ag_axs[0].legend()\n",
    "    ag_axs[1].set_title(f\"Correlation Diff for Agent {ag}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31878ff5f053482490704e1dcc61116a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bottleneck Metric Trials :   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "622146552a0e4b13b7e7d4c1e03b4763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988623628c6f40678334647b5e609d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8400b8be585144b6a908d490b210a17d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Train Epoch::   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from community.funcspec.bottleneck import readout_retrain\n",
    "\n",
    "bottleneck_metrics = readout_retrain(\n",
    "    community,\n",
    "    loaders,\n",
    "    n_classes,\n",
    "    n_agents=n_agents,\n",
    "    n_digits=data_config['n_diff_symbols'],\n",
    "    n_epochs=5,\n",
    "    n_tests=1,\n",
    "    use_tqdm=True,\n",
    "    symbols=True,\n",
    "    force_connections=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.19245008972987526, 0.5120000000000001)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#m = np.array([[0.2, 0.8, 0.4], [0.4, 0.1, 0.9], [0.75, 0.25, 0.25]])\n",
    "m = np.eye(3) * 0.8\n",
    "np.linalg.det(m/np.linalg.norm(m)), np.linalg.det(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8, 1.385640646055102)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(m, 2), np.linalg.norm(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.23499177, 0.24198191, 0.36081415],\n",
       "       [0.24917763, 0.40131578, 0.30859375],\n",
       "       [0.19592927, 0.42002466, 0.10279606]], dtype=float32)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accs = lambda s : bottleneck_metrics[\"accs\"][:, :, s]\n",
    "\n",
    "diffs = [\n",
    "    [diff_metric(bottleneck_metrics[\"accs\"][ag, :, step]) for step in range(3)]\n",
    "    for ag in range(2)\n",
    "]\n",
    "\n",
    "bottleneck_metrics[\"accs\"][..., 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0005433033, 0.0027645489, 0.010405817]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dets = [np.abs(np.linalg.det(accs(s))) / np.linalg.norm(accs(s), 1) for s in range(3)]\n",
    "dets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05698001757264137, 0.12618973851203918, 0.2638481855392456]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ np.abs(diffs[0][s] - diffs[1][s])/2 for s in range(3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9698133"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.norm(accs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45699286, 0.36401972, 0.23505703],\n",
       "       [0.19756787, 0.3508985 , 0.41987857],\n",
       "       [0.39513573, 0.20206657, 0.37076777]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottleneck_metrics[\"accs\"][:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0432749, 0.08366272], [-0.0011862468, -0.15947202]]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float32' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb Cell 66\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y124sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m2\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y124sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m     t_accs \u001b[39m=\u001b[39m ag_accs[t]\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y124sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m     ag_axs[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mbar(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39;49m(t_accs)), (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m t \u001b[39m*\u001b[39m t_accs, label\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDigit \u001b[39m\u001b[39m{\u001b[39;00mt\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y124sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m diff_corrs \u001b[39m=\u001b[39m [diff_max(c) \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m ag_accs\u001b[39m.\u001b[39mT]\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bblossom.ee.ic.ac.uk/home/gb21/Code/ANNs/community-of-agents/notebooks/Funcspec/Symbols.ipynb#Y124sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m ag_axs[\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mbar(\u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(diff_corrs)), diff_corrs)\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'numpy.float32' has no len()"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_accs = bottleneck_metrics[\"accs\"][0]  # target x timesteps x agents\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "for ag, ag_axs in enumerate(axs):\n",
    "    ag_accs = all_accs[..., ag]\n",
    "    for t in range(2):\n",
    "        t_accs = ag_accs[t]\n",
    "        ag_axs[0].bar(range(len(t_accs)), (-1) ** t * t_accs, label=f\"Digit {t}\")\n",
    "\n",
    "    diff_corrs = [diff_max(c) for c in ag_accs.T]\n",
    "    ag_axs[1].bar(range(len(diff_corrs)), diff_corrs)\n",
    "\n",
    "    ag_axs[0].set_title(f\"Retrain Accs for Agent {ag}\")\n",
    "    ag_axs[0].set_ylabel(\"Acc\")\n",
    "    for ax in ag_axs:\n",
    "        ax.set_xlabel(\"Timesteps\")\n",
    "        ax.set_xticks(range(len(t_accs)))\n",
    "        ax.set_xticklabels([\"Before Comms\", \"After Comms\"])\n",
    "        ax.legend()\n",
    "\n",
    "    ag_axs[1].set_title(f\"Retrain Acc Diff for Agent {ag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_accs[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_variations(dataset, index):\n",
    "\n",
    "    original_data, original_label = (d.clone() for d in dataset[index])\n",
    "\n",
    "    scenarios = [\"Original\", \"Same_Count\", \"0s\", \"1s\", \"Inv\"]\n",
    "    labels = [\n",
    "        [original_label],\n",
    "        [original_label],\n",
    "        [torch.tensor([n_classes - 1, 0])],\n",
    "        [torch.tensor([0, n_classes - 1])],\n",
    "        [original_label],\n",
    "    ]\n",
    "    labels = [l * 10 for l in labels]\n",
    "\n",
    "    data_var = {s: [] for s in scenarios}\n",
    "    for l in labels[0]:\n",
    "        data_var[\"Original\"].append(original_data)\n",
    "\n",
    "    dataset.regenerate = True\n",
    "    for i, (lab, s) in enumerate(zip(labels[1:], scenarios[1:])):\n",
    "\n",
    "        def regen_data(l, s):\n",
    "            dataset.data[1][index] = l\n",
    "            return dataset.__getitem__(index, inv=(\"Inv\" in s))[0]\n",
    "\n",
    "        for l in lab:\n",
    "            data_var[s].append(regen_data(l, s))\n",
    "\n",
    "    dataset.regenerate = False\n",
    "    dataset.data[1][index] = original_label\n",
    "    return {s: torch.stack(d).cpu() for s, d in data_var.items()}, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data variations :\n",
    "datas, labels = get_input_variations(datasets[0], 5)\n",
    "datas = {s: process_data(data, flatten=False) for s, data in datas.items()}\n",
    "labels = torch.stack([l for lab in labels for l in lab[:2] if type(lab) is list])\n",
    "create_gifs(\n",
    "    torch.cat([d[:, :, :2, 0, ...] for d in datas.values()], 2),\n",
    "    labels,\n",
    "    \"symbols\",\n",
    "    data_config[\"input_size\"],\n",
    "    \"max_count\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from community.funcspec.correlation import (\n",
    "    v_pearsonr,\n",
    "    get_correlation,\n",
    "    randperm_no_fixed,\n",
    ")\n",
    "\n",
    "perm = lambda s: randperm_no_fixed(s.shape[1])\n",
    "\n",
    "\n",
    "def vect_pearson_diff(h1, h2):\n",
    "    # Returns vectorized pearson correlation for nonequal vectors\n",
    "    mask = (h1 != h2).all(1)\n",
    "    corrs = (\n",
    "        v_pearsonr(h1[mask], h2[mask])[0] if mask.sum() > 0 else v_pearsonr(h1, h2)[0]\n",
    "    )\n",
    "    return corrs.mean()\n",
    "\n",
    "\n",
    "def get_correlations(network, dataset, n_tests=32):\n",
    "\n",
    "    corrs = []\n",
    "\n",
    "    for i in trange(min(n_tests, len(dataset))):\n",
    "\n",
    "        data_dict = get_input_variations(datasets[0], i)[0]\n",
    "        data_dict = {\n",
    "            s: [process_data(d, flatten=not use_conv, device=device)]\n",
    "            for s, d in data_dict.items()\n",
    "        }\n",
    "        # split = int(max(np.floor(data_dict['Original'].shape[2] / batch_size), 1))\n",
    "        # print(f'{data_dict[\"Original\"].shape[2]} input to process, splitting in {split}  batches')\n",
    "        # data_dict = {s : d.split(split, dim=2) for s, d in data_dict.items()}\n",
    "\n",
    "        states = {\n",
    "            s: np.concatenate(\n",
    "                [network(d)[1][-1].clone().cpu().data.numpy() for d in data], 1\n",
    "            )\n",
    "            for s, data in data_dict.items()\n",
    "        }\n",
    "        corrs.append(\n",
    "            np.array(\n",
    "                [\n",
    "                    [\n",
    "                        [vect_pearson_diff(h1[i], h2[i]) for h1 in states.values()]\n",
    "                        for h2 in states.values()\n",
    "                    ]\n",
    "                    for i in range(2)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return np.stack(corrs), states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs, states = get_correlations(community, datasets[0], 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 1, figsize=(4, 7), dpi=120)\n",
    "scenarios = list(states.keys())\n",
    "\n",
    "for i, (ax, c) in enumerate(zip(axs, corrs.mean(0))):\n",
    "    ax = sns.heatmap(\n",
    "        c,\n",
    "        cmap=\"inferno\",\n",
    "        annot=c.round(3).astype(str),\n",
    "        annot_kws={\"fontsize\": 7},\n",
    "        fmt=\"s\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    ax.set_title(f\"Correlations for Ag {i}\")\n",
    "    ax.set_xticks(np.arange(len(scenarios)) + 0.5)\n",
    "    ax.set_xticklabels(scenarios, fontsize=7)\n",
    "    ax.set_yticks(np.arange(len(scenarios)) + 0.5)\n",
    "    ax.set_yticklabels(scenarios, fontsize=7)\n",
    "\n",
    "# fig.colorbar(im)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_same_count_data(dataset, idx):\n",
    "\n",
    "    dataset.regenerate = True\n",
    "    orig_data, orig_label = dataset[idx]\n",
    "    sym_assigns = [dataset.symbol_assignments[l] for l in orig_label]\n",
    "    # print(sym_assigns)\n",
    "\n",
    "    same_count_datas = torch.stack(\n",
    "        [\n",
    "            dataset.__getitem__(idx, symbol_assigns=[s1, s2])[0]\n",
    "            for s1 in sym_assigns[0]\n",
    "            for s2 in sym_assigns[1]\n",
    "        ]\n",
    "    )\n",
    "    same_count_datas_0 = torch.stack(\n",
    "        [\n",
    "            dataset.__getitem__(idx, symbol_assigns=[s1, None])[0]\n",
    "            for s1 in sym_assigns[0]\n",
    "        ]\n",
    "    )\n",
    "    same_count_datas_1 = torch.stack(\n",
    "        [\n",
    "            dataset.__getitem__(idx, symbol_assigns=[None, s2])[0]\n",
    "            for s2 in sym_assigns[1]\n",
    "        ]\n",
    "    )\n",
    "    # same_count_datas = torch.stack([ torch.stack((d1[:, 0], d2[:, 1])) for d1 in same_count_datas_0 for d2 in same_count_datas_1])\n",
    "\n",
    "    dataset.regenerate = False\n",
    "\n",
    "    return same_count_datas, [same_count_datas_0, same_count_datas_1], orig_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 10\n",
    "dataset = datasets[0]\n",
    "data, target = dataset[idx]\n",
    "same_count_datas, same_count_datas_per_ag, original_data = get_same_count_data(\n",
    "    dataset, idx\n",
    ")\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(5, 5))\n",
    "fig.suptitle(\"Same Count Data\")\n",
    "\n",
    "nrows, ncols = same_count_datas.shape[:2]\n",
    "\n",
    "subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "\n",
    "for ag, subfig in enumerate(subfigs):\n",
    "    data = same_count_datas_per_ag[ag][:5]\n",
    "    subfig.suptitle(f\"Agent {ag} : Count {target[ag]}\")\n",
    "    axs = subfig.subplots(nrows=1, ncols=len(data), sharey=False)\n",
    "    if len(data) == 1:\n",
    "        axs = np.array([axs])\n",
    "    for p, ax in enumerate(axs.flatten()):\n",
    "        ax.imshow(data[p, -1, ag])\n",
    "        # ax.set_title(f'Agent {p}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_count_states = [\n",
    "    community(process_data(d, device=device))[1][-1].cpu().data.numpy()\n",
    "    for d in same_count_datas_per_ag\n",
    "]\n",
    "same_count_corrs = np.array(\n",
    "    [\n",
    "        [pearsonr(h1, h2)[0] for h1 in states[ag] for h2 in states[ag]]\n",
    "        for ag, states in enumerate(same_count_states)\n",
    "    ]\n",
    ").reshape(-1, 3, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_count_states = (\n",
    "    community(process_data(same_count_datas, device=device))[1][-1].cpu().data.numpy()\n",
    ")\n",
    "same_count_corrs = np.array(\n",
    "    [\n",
    "        [pearsonr(h1, h2)[0] for h1 in states for h2 in states]\n",
    "        for ag, states in enumerate(same_count_states)\n",
    "    ]\n",
    ").reshape(-1, 9, 9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_count_states.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for corr, data in zip(same_count_corrs, same_count_corrs):\n",
    "    plt.figure()\n",
    "    plt.imshow(corr)\n",
    "    plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from community.funcspec.single_model_loop import compute_all_metrics\n",
    "from community.funcspec.correlation import get_pearson_metrics, fixed_information_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 8\n",
    "dataset = datasets[0]\n",
    "data, target = dataset[idx]\n",
    "same_count_datas = fixed_information_data(data, target, 0)\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(5, 5))\n",
    "fig.suptitle(\"Same Count Data\")\n",
    "\n",
    "nrows, ncols = same_count_datas.shape[:2]\n",
    "\n",
    "subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "\n",
    "for ag, subfig in enumerate(subfigs):\n",
    "    data = same_count_datas_per_ag[ag]\n",
    "    subfig.suptitle(f\"Agent {ag} : Count {target[ag]}\")\n",
    "    axs = subfig.subplots(nrows=1, ncols=len(data), sharey=False)\n",
    "    if len(data) == 1:\n",
    "        axs = np.array([axs])\n",
    "    for p, ax in enumerate(axs.flatten()):\n",
    "        ax.imshow(data[p, -1, ag])\n",
    "        # ax.set_title(f'Agent {p}')\n",
    "\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = next(iter(loaders[0]))\n",
    "data = process_data(data, False)\n",
    "same_count_datas = fixed_information_data(data, target, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(15, 15))\n",
    "fig.suptitle(\"Same Count Data\")\n",
    "\n",
    "subfigs = fig.subfigures(nrows=len(same_count_datas), ncols=1)\n",
    "\n",
    "for d, subfig in enumerate(subfigs):\n",
    "    data = same_count_datas[d]\n",
    "    subfig.suptitle(f\"Item {d} : Count {target[d, 0]}\")\n",
    "    axs = subfig.subplots(nrows=2, ncols=5, sharey=False)\n",
    "    if len(data) == 1:\n",
    "        axs = np.array([axs])\n",
    "    for ag, ag_ax in enumerate(axs):\n",
    "        for p, ax in enumerate(ag_ax.flatten()):\n",
    "            ax.imshow(data[-1, ag, p, 0].cpu())\n",
    "        # ax.set_title(f'Agent {p}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('community')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c46eabf39b4d4e6cb6668853226ee702b3f0cb279968f228c052b13b97983d9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
